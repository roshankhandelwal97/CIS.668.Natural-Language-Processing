{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34nwFy4M5w-0"
      },
      "source": [
        "**IST664: Week 4 Lab**\n",
        "\n",
        "In the class we learned about context-free grammar, dependency grammar, and parsing. We will exercise these concepts using NLTK. Our focus is on understanding how grammars represent language using classical algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DGWWImT3QdW"
      },
      "source": [
        "**Part 1 - Context-Free Grammar and Parsing**\n",
        "\n",
        "The parse_cfg function is given to take a normal string representation of a CFG grammar and convert it to a form that the parsers can use. Here is an example grammar. [Note: String literals can span multiple lines. We can use triple quotes to tell Python that this is the case, as seen in the above example.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8wADjvN5uN7"
      },
      "source": [
        "import nltk\n",
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  VP -> V NP | V NP PP\n",
        "  PP -> P NP\n",
        "  V -> \"saw\" | \"ate\" | \"walked\"\n",
        "  NP -> Prop | Det N | Det N PP\n",
        "  Prop -> \"John\" | \"Mary\" | \"Bob\"\n",
        "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
        "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
        "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
        "  \"\"\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we define a recursive descent parser from this grammar and test it on a short sentence. The recursive descent parser uses top-down approach in parsing and is described in the NLTK book (see section 8.4, https://www.nltk.org/book/ch08.html)."
      ],
      "metadata": {
        "id": "35Fd-sWiBxfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # top-down method: recursive descent parsing\n",
        "# create the parser from a grammar\n",
        "rd_parser = nltk.RecursiveDescentParser(grammar)"
      ],
      "metadata": {
        "id": "OXGLgFqeDBzu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we define example sentences to test our parsers, we can use the normal NLTK function nltk.word_tokenize() for tokenization, but a shorter way to tokenize a string with just words and no special symbols is to use the Python “split” function. With no argument, it will produce a list of tokens that were separated by white space."
      ],
      "metadata": {
        "id": "lE-0rWbiD0z_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dppMX25BBG85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d530d6b3-44ca-49c7-f496-4c05787cd3b0"
      },
      "source": [
        "senttext = \"Mary saw Bob\"\n",
        "sentlist = senttext.split()\n",
        "print(sentlist)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mary', 'saw', 'Bob']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run the parse function on the list of tokens. The parser returns a generator for the list of all trees that it found.\n",
        "trees = rd_parser.parse(sentlist)\n",
        "\n",
        "# convert the generator to a list\n",
        "treelist = list(trees)\n",
        "\n",
        "# what type is an individual tree? The NLTK has a type called nltk.tree.Tree for each tree.\n",
        "print(type(treelist[0]))\n",
        "\n",
        "# print the tree structures. Note that this parser returns n (all) the parse trees,\n",
        "# so we can try this out on a syntactically ambiguous sentence.\n",
        "# Here we just iterate over the generator to print all the trees.\n",
        "for tree in treelist:\n",
        "\tprint (tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1txud3HDEbLV",
        "outputId": "2165a97d-0b58-45f5-bc6d-d0fec0647760"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'nltk.tree.tree.Tree'>\n",
            "(S (NP (Prop Mary)) (VP (V saw) (NP (Prop Bob))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLV5ZKQD-p4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6c31b7-f1e5-4c32-f607-4ede2d0980b0"
      },
      "source": [
        "sent2list = \"John saw the man in the park with a telescope\".split()\n",
        "for tree in rd_parser.parse(sent2list):\n",
        "\tprint (tree)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (Prop John))\n",
            "  (VP\n",
            "    (V saw)\n",
            "    (NP\n",
            "      (Det the)\n",
            "      (N man)\n",
            "      (PP\n",
            "        (P in)\n",
            "        (NP\n",
            "          (Det the)\n",
            "          (N park)\n",
            "          (PP (P with) (NP (Det a) (N telescope))))))))\n",
            "(S\n",
            "  (NP (Prop John))\n",
            "  (VP\n",
            "    (V saw)\n",
            "    (NP (Det the) (N man))\n",
            "    (PP\n",
            "      (P in)\n",
            "      (NP\n",
            "        (Det the)\n",
            "        (N park)\n",
            "        (PP (P with) (NP (Det a) (N telescope)))))))\n",
            "(S\n",
            "  (NP (Prop John))\n",
            "  (VP\n",
            "    (V saw)\n",
            "    (NP (Det the) (N man) (PP (P in) (NP (Det the) (N park))))\n",
            "    (PP (P with) (NP (Det a) (N telescope)))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you try other sentences, don’t put the punctuation at the end because we didn’t include any punctuation in the grammar.\n",
        "\n",
        "We can add words to our grammar in order to parse other sentences. We add more words in this grammar below. Note that as we change the grammar, we create a new parser that takes this revised grammar as the input."
      ],
      "metadata": {
        "id": "-JcslxjLGTSI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGT9sL2y_8Td"
      },
      "source": [
        "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  VP -> V NP | V NP PP\n",
        "  PP -> P NP\n",
        "  V -> \"saw\" | \"ate\" | \"walked\" | \"shot\"\n",
        "  NP -> Prop | Det N | Det N PP\n",
        "  Prop -> \"John\" | \"Mary\" | \"Bob\" | \"I\"\n",
        "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
        "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\" | \"elephant\" | \"pajamas\"\n",
        "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
        "  \"\"\")\n",
        "\n",
        "rd_parser = nltk.RecursiveDescentParser(groucho_grammar)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBnFhZesBBgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f2b606-1887-4204-b76b-cd73f7231e19"
      },
      "source": [
        "# try sent4 with the recursive descent parser on groucho grammar\n",
        "sent4list = \"I shot an elephant in my pajamas\".split()\n",
        "for tree in rd_parser.parse(sent4list):\n",
        "\tprint (tree)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (Prop I))\n",
            "  (VP\n",
            "    (V shot)\n",
            "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n",
            "(S\n",
            "  (NP (Prop I))\n",
            "  (VP\n",
            "    (V shot)\n",
            "    (NP (Det an) (N elephant))\n",
            "    (PP (P in) (NP (Det my) (N pajamas)))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To demonstrate further development of this grammar, suppose that we want to be able to parse sentences like “Book that flight”. For this grammar, we need for sentences to be just a Verb Phrase, and we need the three words to be included where “book” is a verb, “that” is a determiner, and “flight” is a noun."
      ],
      "metadata": {
        "id": "EwfkOM7-HcS4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSgqQwI1DYPu"
      },
      "source": [
        "flight_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP VP | VP\n",
        "  VP -> V NP | V NP PP\n",
        "  PP -> P NP\n",
        "  V -> \"saw\" | \"ate\" | \"walked\" | \"shot\" | \"book\" | \"prefer\" | \"want\"\n",
        "  NP -> Prop | Det N | Det N PP\n",
        "  Prop -> \"John\" | \"Mary\" | \"Bob\" | \"I\" | \"Houston\" | \"Jack\"\n",
        "  Det -> \"a\" | \"an\" | \"the\" | \"my\" | \"that\"\n",
        "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\" | \"elephant\" | \"pajamas\" | \"flight\"\n",
        "  P -> \"in\" | \"on\" | \"by\" | \"with\" | \"through\" | \"with\" | \"to\"\n",
        "  \"\"\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31VsyTTdEAvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57981fa4-bb87-4ee2-9079-945d1f630c1e"
      },
      "source": [
        "# make a recursive descent parser and parse the sentence\n",
        "rd_parser = nltk.RecursiveDescentParser(flight_grammar)\n",
        "sent5list = 'book that flight'.split()\n",
        "for tree in rd_parser.parse(sent5list):\n",
        "\tprint (tree)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (VP (V book) (NP (Det that) (N flight))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flight_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP VP | VP\n",
        "  VP -> V NP | V NP PP\n",
        "  PP -> P NP\n",
        "  V -> \"saw\" | \"ate\" | \"walked\" | \"shot\" | \"book\" | \"prefer\" | \"want\"\n",
        "  NP -> Prop | Det N | Det N PP\n",
        "  Prop -> \"John\" | \"Mary\" | \"Bob\" | \"I\" | \"Houston\" | \"Jack\"\n",
        "  Det -> \"a\" | \"an\" | \"the\" | \"my\" | \"that\"\n",
        "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\" | \"elephant\" | \"pajamas\" | \"flight\"\n",
        "  P -> \"in\" | \"on\" | \"by\" | \"with\" | \"through\" | \"with\" | \"to\"\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "aTjIu8saN9ae"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZOQ0b7CEoaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a10fe4-cd9b-4c4a-b8c3-93e025c5e321"
      },
      "source": [
        "# 4.1. Starting with the flight grammar, add the CFG rules to parse the following three sentences.\n",
        "# (Note that I have left the “.” off the end of each sentence.)\n",
        "\n",
        "\n",
        "# I prefer a flight through Houston\n",
        "\n",
        "rd_parser = nltk.RecursiveDescentParser(flight_grammar)\n",
        "sent5list1 = 'prefer a flight through Houston'.split()\n",
        "print(sent5list1)\n",
        "for tree1 in rd_parser.parse(sent5list1):\n",
        "\tprint(tree1)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prefer', 'a', 'flight', 'through', 'Houston']\n",
            "(S\n",
            "  (VP\n",
            "    (V prefer)\n",
            "    (NP (Det a) (N flight) (PP (P through) (NP (Prop Houston))))))\n",
            "(S\n",
            "  (VP\n",
            "    (V prefer)\n",
            "    (NP (Det a) (N flight))\n",
            "    (PP (P through) (NP (Prop Houston)))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jack walked with the dog\n",
        "\n",
        "rd_parser = nltk.RecursiveDescentParser(flight_grammar)\n",
        "sent5list1 = 'Jack walked with the dog'.split()\n",
        "for tree1 in rd_parser.parse(sent5list1):\n",
        "\tprint(tree1)"
      ],
      "metadata": {
        "id": "XDx0yf7RLbVA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I want to book that flight\n",
        "\n",
        "rd_parser = nltk.RecursiveDescentParser(flight_grammar)\n",
        "sent5list3 = 'I want to book that flight'.split()\n",
        "for tree3 in rd_parser.parse(sent5list3):\n",
        "\tprint(tree3)"
      ],
      "metadata": {
        "id": "YYxIOYYoVbUE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaL7cRS-FSJ-"
      },
      "source": [
        "# Now let's look at probablisitic CFG grammar with verb subcategories\n",
        "# transitive (TranV), intransitive (InV) and dative (DatV) verbs\n",
        "prob_grammar = nltk.PCFG.fromstring(\"\"\"\n",
        "  S -> NP VP [0.9]| VP  [0.1]\n",
        "  VP -> TranV NP [0.3]\n",
        "  VP -> InV  [0.3]\n",
        "  VP -> DatV NP PP  [0.4]\n",
        "  PP -> P NP   [1.0]\n",
        "  TranV -> \"saw\" [0.2] | \"ate\" [0.2] | \"walked\" [0.2] | \"shot\" [0.2] | \"book\" [0.2]\n",
        "  InV -> \"ate\" [0.5] | \"walked\" [0.5]\n",
        "  DatV -> \"gave\" [0.2] | \"ate\" [0.2] | \"saw\" [0.2] | \"walked\" [0.2] | \"shot\" [0.2]\n",
        "  NP -> Prop [0.2]| Det N [0.4] | Det N PP [0.4]\n",
        "  Prop -> \"John\" [0.25]| \"Mary\" [0.25] | \"Bob\" [0.25] | \"I\" [0.25]\n",
        "  Det -> \"a\" [0.2] | \"an\" [0.2] | \"the\" [0.2] | \"my\" [0.2] | \"that\" [0.2]\n",
        "  N -> \"man\" [0.15] | \"dog\" [0.15] | \"cat\" [0.15] | \"park\" [0.15] | \"telescope\" [0.1] | \"flight\" [0.1] | \"elephant\" [0.1] | \"pajamas\" [0.1]\n",
        "  P -> \"in\" [0.2] | \"on\" [0.2] | \"by\" [0.2] | \"with\" [0.2] | \"through\" [0.2]\n",
        "  \"\"\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bfT4lvbj3a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3ffa73-363a-4db3-dda7-6dc235f108bd"
      },
      "source": [
        "# create a viterbi parser, a parser that expects a PCFG\n",
        "viterbi_parser = nltk.ViterbiParser(prob_grammar)\n",
        "# use its parse function on a list of tokens\n",
        "for tree in viterbi_parser.parse(['John', 'saw', 'a', 'telescope']):\n",
        "    print (tree)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (Prop John))\n",
            "  (VP (TranV saw) (NP (Det a) (N telescope)))) (p=2.16e-05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RopuuGmldTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd2cce50-30aa-4993-84a4-07e8e0e8cd7c"
      },
      "source": [
        "# parse some other sentences\n",
        "# this parser chooses to return the highest probability tree\n",
        "for tree in viterbi_parser.parse(sent2list):\n",
        "    print (tree)\n",
        "\n",
        "for tree in viterbi_parser.parse(sent4list):\n",
        "    print (tree)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (Prop John))\n",
            "  (VP\n",
            "    (DatV saw)\n",
            "    (NP\n",
            "      (Det the)\n",
            "      (N man)\n",
            "      (PP (P in) (NP (Det the) (N park))))\n",
            "    (PP (P with) (NP (Det a) (N telescope))))) (p=1.65888e-10)\n",
            "(S\n",
            "  (NP (Prop I))\n",
            "  (VP\n",
            "    (DatV shot)\n",
            "    (NP (Det an) (N elephant))\n",
            "    (PP (P in) (NP (Det my) (N pajamas))))) (p=4.608e-08)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2 - Dependency Grammar and Parsing**\n",
        "\n",
        "NLTK also allows you to write dependency grammars which just have to show the relationships between individual words. Ideally, we would like to have labeled relationships, but the NLTK dependency grammars have just unlabeled relationships. This is described in Section 8.5 of the NLTK book. Here is a grammar for the groucho example."
      ],
      "metadata": {
        "id": "ZypkT84BLcZu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkLSbvDDos0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d729ad9-1487-40a5-9bb2-3803578e7c08"
      },
      "source": [
        "groucho_dep_grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
        "  'shot' -> 'I' | 'elephant' | 'in'\n",
        "  'elephant' -> 'an' | 'in'\n",
        "  'in' -> 'pajamas'\n",
        "  'pajamas' -> 'my'\n",
        "  \"\"\")\n",
        "print (groucho_dep_grammar)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependency grammar with 7 productions\n",
            "  'shot' -> 'I'\n",
            "  'shot' -> 'elephant'\n",
            "  'shot' -> 'in'\n",
            "  'elephant' -> 'an'\n",
            "  'elephant' -> 'in'\n",
            "  'in' -> 'pajamas'\n",
            "  'pajamas' -> 'my'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFlH9wztplQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c13b18-9371-4ea2-97a2-9ebb291cd401"
      },
      "source": [
        "# We can try this out on our ambiguous sentence and look at the trees that it gets.\n",
        "pdp = nltk.ProjectiveDependencyParser(groucho_dep_grammar)\n",
        "glist = 'I shot an elephant in my pajamas'.split()\n",
        "# use the parse function to parse a list of tokens\n",
        "trees = pdp.parse(glist)\n",
        "for tree in trees:\n",
        "    print (tree)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(shot I (elephant an (in (pajamas my))))\n",
            "(shot I (elephant an) (in (pajamas my)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHcE2rk6wBTI"
      },
      "source": [
        "# 4.2. Please modify the dependency grammar above such that only the second tree will be the output\n",
        "\n",
        "groucho_dep_grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
        "  'elephant' -> 'an' | 'in'\n",
        "  'in' -> 'pajamas'\n",
        "  'pajamas' -> 'my'\n",
        "  \"\"\")\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}