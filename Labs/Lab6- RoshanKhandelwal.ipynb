{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P4qX2BhcVYy"
      },
      "source": [
        "# IST664 - Week 6 Lab: Introduction to spaCy\n",
        "\n",
        "SpaCy is an open source natural language processing library written by  Matthew Honnibal and Ines Montani. Most of spaCy is written natively in Python. Unlike NLTK, which was designed for teaching and research, spaCy was created from the start to support production applications - real world activities that require natural language processing. SpaCy uses a \"pipeline\" metaphor such that input documents and data go through a variety of typical processing stages where each stage feeds into the next one. Examples of these stages include tokenization, part of speech tagging, named entity recognition, and transformation into word vectors.\n",
        "\n",
        "Try searching for \"spaCy\" on Kaggle.com. At this writing there were more than 4600 projects that used spaCy. Part of the appeal is that spaCy makes it easy to get started with a project. SpaCy contains support for dozens of different languages and its integration with word- and sentence-embedding approaches provides access to the advantages of pre-trained deep learning models.\n",
        "\n",
        "Although you have seen spaCy briefly before in previous labs, in this lab you will get a more comprehensive view of the architecture and capabilities of spaCy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFA8yhi5cVY0"
      },
      "source": [
        "Sections of this lab:\n",
        "- Basics: Getting Started\n",
        "- Lemmatization\n",
        "- Token Extracting / Removing / Transforming\n",
        "- Sentence Segmentation\n",
        "- Part of Speech Tagging\n",
        "- Named Entity Recognition\n",
        "- Dependency Parsing\n",
        "- Word Vectors\n",
        "- Sentence Similarity\n",
        "- Customizing pipeline components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI5UX3AicVY5"
      },
      "source": [
        "# Basics: Getting Started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOF7T14dcVY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8d7790-2c2e-4301-d2c7-dbcf8f3719d9"
      },
      "source": [
        "# Every spaCy project begins with importing the package and\n",
        "# instantiating a processing object that is initialized with a particular\n",
        "# language model. In this case we will start with English:\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# That's equivalent to:\n",
        "# import en_core_web_sm\n",
        "# nlp = en_core_web_sm.load()\n",
        "\n",
        "type(nlp)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.lang.en.English"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5kmYa0aiLxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a97b1ed-b5dc-4abf-ecb1-ca837cfda662"
      },
      "source": [
        "# There are lots of things this object can do. Let's use\n",
        "# dir to get a list of them:\n",
        "\n",
        "[m for m in dir(nlp) if m[0] != \"_\"]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Defaults',\n",
              " 'add_pipe',\n",
              " 'analyze_pipes',\n",
              " 'batch_size',\n",
              " 'begin_training',\n",
              " 'component',\n",
              " 'component_names',\n",
              " 'components',\n",
              " 'config',\n",
              " 'create_optimizer',\n",
              " 'create_pipe',\n",
              " 'create_pipe_from_source',\n",
              " 'default_config',\n",
              " 'default_error_handler',\n",
              " 'disable_pipe',\n",
              " 'disable_pipes',\n",
              " 'disabled',\n",
              " 'enable_pipe',\n",
              " 'evaluate',\n",
              " 'factories',\n",
              " 'factory',\n",
              " 'factory_names',\n",
              " 'from_bytes',\n",
              " 'from_config',\n",
              " 'from_disk',\n",
              " 'get_factory_meta',\n",
              " 'get_factory_name',\n",
              " 'get_pipe',\n",
              " 'get_pipe_config',\n",
              " 'get_pipe_meta',\n",
              " 'has_factory',\n",
              " 'has_pipe',\n",
              " 'initialize',\n",
              " 'lang',\n",
              " 'make_doc',\n",
              " 'max_length',\n",
              " 'meta',\n",
              " 'path',\n",
              " 'pipe',\n",
              " 'pipe_factories',\n",
              " 'pipe_labels',\n",
              " 'pipe_names',\n",
              " 'pipeline',\n",
              " 'rehearse',\n",
              " 'remove_pipe',\n",
              " 'rename_pipe',\n",
              " 'replace_listeners',\n",
              " 'replace_pipe',\n",
              " 'resume_training',\n",
              " 'select_pipes',\n",
              " 'set_error_handler',\n",
              " 'set_factory_meta',\n",
              " 'to_bytes',\n",
              " 'to_disk',\n",
              " 'tokenizer',\n",
              " 'update',\n",
              " 'use_params',\n",
              " 'vocab']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJbnfdzZcVY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea2663f5-2c56-41e9-a7f9-edebe9b9b9b3"
      },
      "source": [
        "# At the most basic level, and at the beginning of most\n",
        "# NLP pipelines, we tokenize a document:\n",
        "doc = nlp(\"Hello World!\") # This is the most basic way to use the instance\n",
        "type(doc), len(doc) # What is the result?"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(spacy.tokens.doc.Doc, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTLkJurQi9U1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24224f8-870b-4fcf-b801-0e9bf026e0de"
      },
      "source": [
        "# A spaCy \"tokens-doc\" behaves like a list, such that\n",
        "# we can use a list comprehension to access the individual\n",
        "# tokens in the document:\n",
        "[token.text for token in doc]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'World', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uayw2T4rcVY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ae012f-89b1-4097-b8c4-92babe736cad"
      },
      "source": [
        "# And because it behaves like a list, we can also use\n",
        "# slicing to get access to the individual tokens.\n",
        "first_token = doc[0] # Slice off the first token\n",
        "print(type(first_token)) # What is its type?\n",
        "print(first_token.text) # Show the text of the token"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'spacy.tokens.token.Token'>\n",
            "Hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbALUS2kcVY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea138567-23a2-411e-d5f3-c8e34ce5bf1b"
      },
      "source": [
        "# In spaCy terminology, a span is any contiguous set of tokens.\n",
        "# Spans are often used to break up a document into sentences. Here\n",
        "# we are just using slicing to create a span with the first two\n",
        "# of our three tokens.\n",
        "span = doc[0:2]\n",
        "[token.text for token in span]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'World']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8cGZAmUj_vx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2af4a9-3296-47a9-ce6b-e4a1eda6d084"
      },
      "source": [
        "# For this first exercise, tokenize a longer text excerpted from Wikipedia.\n",
        "# Use slicing to show the first five tokens:\n",
        "\n",
        "longtext = \"\"\"A neural network is either a biological neural network or an\n",
        "artificial neural network for solving artificial intelligence (AI) problems.\n",
        "The connections of the biological neuron are modeled as weights. A positive\n",
        "weight reflects an excitatory connection, while negative values mean\n",
        "inhibitory connections.\"\"\"\n",
        "\n",
        "# 6.1: Tokenize longtext\n",
        "doc = nlp(longtext)\n",
        "\n",
        "# 6.2: Display the texts of tokens in a span consisting of the first five tokens\n",
        "span = doc[0:5]\n",
        "print(\"first five tokens\", [token.text for token in span])\n",
        "\n",
        "# 6.2a: (Challenge) Use Python slicing notation to show the last five tokens\n",
        "span = doc[-5:]\n",
        "print(\"last five tokens\", [token.text for token in span])\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first five tokens ['A', 'neural', 'network', 'is', 'either']\n",
            "last five tokens ['mean', '\\n', 'inhibitory', 'connections', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5irACZSv7pA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c481f69f-3484-4043-d281-3d1097154c13"
      },
      "source": [
        "# SpaCy uses the language model to make better tokenization decisions. Let's\n",
        "# compare spaCy tokenization with the primitive use of split(). Remember that\n",
        "# split() defaults to splitting on spaces.\n",
        "headline = \"Rare Bird’s Detection Highlights Promise of ‘Environmental DNA’\"\n",
        "\n",
        "splitspacy = nlp(headline) # Use spaCy tokenization\n",
        "splitspace = headline.split() # Use simple splitting on spaces\n",
        "\n",
        "print(\"SpaCy tokens:\")\n",
        "print([t.text for t in splitspacy])\n",
        "print(len(splitspacy), \"tokens.\")\n",
        "\n",
        "print(\"\\nSimple splitting:\")\n",
        "print([s for s in splitspace])\n",
        "print(len(splitspace), \"tokens.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpaCy tokens:\n",
            "['Rare', 'Bird', '’s', 'Detection', 'Highlights', 'Promise', 'of', '‘', 'Environmental', 'DNA', '’']\n",
            "11 tokens.\n",
            "\n",
            "Simple splitting:\n",
            "['Rare', 'Bird’s', 'Detection', 'Highlights', 'Promise', 'of', '‘Environmental', 'DNA’']\n",
            "8 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC32D3YIKbZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12fdab61-d1e8-4c1d-fd55-378ca6f80fa2"
      },
      "source": [
        "# Why do you think it might be helpful to tokenize the possessive \"Bird's\" into\n",
        "# two tokens? Add a comment that explains your reasoning. Then find or write\n",
        "# a sentence that contains a hyphenated noun phrase. How does spaCY treat that?\n",
        "\n",
        "# Better understanding for nouns and entities\n",
        "\n",
        "# 6.2b: Use spaCy to tokenize a sentence that contains a hyphenated phrase.\n",
        "\n",
        "sentence = \"That was a well-timed shot\"\n",
        "doc = nlp(sentence)\n",
        "\n",
        "print([token.text for token in doc])\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['That', 'was', 'a', 'well', '-', 'timed', 'shot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9KnXfE9cVY9"
      },
      "source": [
        "# Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdBuIUPRcVY-"
      },
      "source": [
        "Lemmatization is the process of reducing inflected forms, sometimes derivationally related forms of a word to a common base form. This reduced form or root word is called a lemma. Lemmas have an advantage over simple stemming: Lemmas are always dictionary words. Lemmatizing can be a valuable data reduction technique because it aggregates various inflective forms of a word down to a single root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afi7fWJpcVY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50fc510-be35-468a-c590-8c5089cf5bd6"
      },
      "source": [
        "# Demonstrate spaCy lemmatization with a verb form\n",
        "text = \"am are is\" # All variations on the verb \"to be\"\n",
        "\n",
        "# Note that the underscore following the attribute name in\n",
        "# the expression token.lemma_ provides the human readable form.\n",
        "[token.lemma_ for token in nlp(text)]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['be', 'be', 'be']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r1LTkjOCjOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46962d6e-bd5d-4f82-a414-c884309c5e39"
      },
      "source": [
        "# Look at the non-text form of the lemma:\n",
        "\n",
        "# 6.3: use token.lemma instead of token.lemma_\n",
        "[token.lemma_ for token in nlp(text)]\n",
        "\n",
        "\n",
        "# Write a comment describing what you see. These values are\n",
        "# ID numbers for spaCy's \"StringStore.\" More information here:\n",
        "# https://spacy.io/usage/spacy-101#vocab"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['be', 'be', 'be']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "oRc6MHIhcVY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6fdfc4-fc28-457d-dae9-9139ae65abcf"
      },
      "source": [
        "# Here's another example\n",
        "text = \"look looks looked\"\n",
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    print(\"token:{} -> lemma:{}\".format(token.text,token.lemma_ ))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token:look -> lemma:look\n",
            "token:looks -> lemma:looks\n",
            "token:looked -> lemma:look\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbqv-p5BG-mV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0c8052-1bbd-47f1-aacc-ef25e0986168"
      },
      "source": [
        "# Add your own example, this time using different forms of a noun\n",
        "\n",
        "# 6.4: Lemmatize two or more inflective forms of a noun\n",
        "\n",
        "text = \"cat cats\"\n",
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    print(\"token:{} -> lemma:{}\".format(token.text,token.lemma_ ))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token:cat -> lemma:cat\n",
            "token:cats -> lemma:cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPh2OEW9cVZD"
      },
      "source": [
        "# Token Extracting / Removing / Transforming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0_iGcUicVZE"
      },
      "source": [
        "Here's an overview of all of the bound methods that a token has. When creating an NLP pipeline, it is incredibly helpful not to have to write Python routines to do these tasks.\n",
        "\n",
        "|Attribute Name\t|Type|Description                                                                    |\n",
        "|:--------------------:|:---------:|:------------------------------------------------------------------------------------------------------------------------------------:|\n",
        "| lemma              | int     | Base form of the token, with no inflectional suffixes.                                                                             |\n",
        "| lemma_             | unicode | Base form of the token, with no inflectional suffixes.                                                                             |\n",
        "| norm               | int     | The token’s norm, i.e. a normalized form of the token text. Usually set in the language’s tokenizer exceptions or norm exceptions. |\n",
        "| norm_              | unicode | The token’s norm, i.e. a normalized form of the token text. Usually set in the language’s tokenizer exceptions or norm exceptions. |\n",
        "| lower              | int     | Lowercase form of the token.                                                                                                       |\n",
        "| lower_             | unicode | Lowercase form of the token text. Equivalent to Token.text.lower().                                                                |\n",
        "| shape              | int     | Transform of the tokens’s string, to show orthographic features. For example, “Xxxx” or “dd”.                                      |\n",
        "| shape_             | unicode | Transform of the tokens’s string, to show orthographic features. For example, “Xxxx” or “dd”.                                      |\n",
        "| prefix             | int     | Hash value of a length-N substring from the start of the token. Defaults to N=1.                                                   |\n",
        "| prefix_            | unicode | A length-N substring from the start of the token. Defaults to N=1.                                                                 |\n",
        "| suffix             | int     | Hash value of a length-N substring from the end of the token. Defaults to N=3.                                                     |\n",
        "| suffix_            | unicode | Length-N substring from the end of the token. Defaults to N=3.                                                                     |\n",
        "| is_alpha           | bool    | Does the token consist of alphabetic characters? Equivalent to token.text.isalpha().                                               |\n",
        "| is_ascii           | bool    | Does the token consist of ASCII characters? Equivalent to all(ord(c) < 128 for c in token.text).                                   |\n",
        "| is_digit           | bool    | Does the token consist of digits? Equivalent to token.text.isdigit().                                                              |\n",
        "| is_lower           | bool    | Is the token in lowercase? Equivalent to token.text.islower().                                                                     |\n",
        "| is_upper           | bool    | Is the token in uppercase? Equivalent to token.text.isupper().                                                                     |\n",
        "| is_title           | bool    | Is the token in titlecase? Equivalent to token.text.istitle().                                                                     |\n",
        "| is_punct           | bool    | Is the token punctuation?                                                                                                          |\n",
        "| is_left_punct      | bool    | Is the token a left punctuation mark, e.g. (?                                                                                      |\n",
        "| is_right_punct     | bool    | Is the token a right punctuation mark, e.g. )?                                                                                     |\n",
        "| is_space           | bool    | Does the token consist of whitespace characters? Equivalent to token.text.isspace().                                               |\n",
        "| is_bracket         | bool    | Is the token a bracket?                                                                                                            |\n",
        "| is_quote           | bool    | Is the token a quotation mark?                                                                                                     |\n",
        "| is_currency V2.0.8 | bool    | Is the token a currency symbol?                                                                                                    |\n",
        "| like_url           | bool    | Does the token resemble a URL?                                                                                                     |\n",
        "| like_num           | bool    | Does the token represent a number? e.g. “10.9”, “10”, “ten”, etc.                                                                  |\n",
        "| like_email         | bool    | Does the token resemble an email address?                                                                                          |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLANATg8cVZE"
      },
      "source": [
        "### Extracting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZySKnJrYcVZE"
      },
      "source": [
        "The list of attributes that spaCy makes available on the token object provide a variety of type tests. The is_ attributes allow testing for alpahnumeric, uppercase, title case, left punctuation mark, right punctuation mark, any punctuation mark, a bracket, a quote mark or a currency symbol. These are all very helpful in navigating within a string of tokens: Later we will show a search capability that allows us to include these in pattern matching.\n",
        "\n",
        "There are also three \"like\" attributes that show if a token looks like a web address, a numeric string, or an email address.\n",
        "\n",
        "Let's run some tests on a long and complex sentence from Wikipedia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRQSZrZhcVZF"
      },
      "source": [
        "text='''An information retrieval technique using latent semantic structure was\n",
        "patented in 1988 (US Patent 4,839,853, now expired) by Scott Deerwester,\n",
        "Susan Dumais, George Furnas, Richard Harshman, Thomas Landauer, Karen Lochbaum\n",
        "and Lynn Streeter. In the context of its application to information retrieval,\n",
        "it is sometimes called latent semantic indexing (LSI).'''"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5TMwLVFcVZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b085270a-cb32-4e8a-e802-ca84296ff37a"
      },
      "source": [
        "my_list=[] # Initialize a blank list\n",
        "doc = nlp(text) # Tokenize the text string\n",
        "for token in doc: # Check each token\n",
        "    if token.is_punct: # Run the bound method\n",
        "        my_list.append(token) # Append to the list\n",
        "\n",
        "for item in my_list: # Review each item in the list\n",
        "    print(item) # Print the item"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\n",
            ",\n",
            ")\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            ".\n",
            ",\n",
            "(\n",
            ")\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na0scT-N5mYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9a2be2-a9b4-4d07-ef9e-6553cb8fa127"
      },
      "source": [
        "# Now do something similar but use a list comprehension\n",
        "[tok for tok in doc if tok.is_left_punct]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(, (]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lchVjYGl6p69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac963ef-a484-48d1-bbc1-dc6b79f85c2d"
      },
      "source": [
        "# Add a line of code to display right punctuation\n",
        "\n",
        "# 6.5: Use the bound method to detect and print right puncutation\n",
        "[tok for tok in doc if tok.is_right_punct]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[), )]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNHFsCK064aJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2fffcea-1117-44f5-edae-6d3f153eb89c"
      },
      "source": [
        "# Add a line of code to detect tokens that seem like numbers\n",
        "\n",
        "# 6.6: Use the bound method to detect and display numbers\n",
        "[tok for tok in doc if tok.like_num]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1988, 4,839,853]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLuAkiwqsp4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "2cfc7525-0a1e-46ef-f8e0-955f1c524a44"
      },
      "source": [
        "# For diagnostic purposes, it may be useful to examine these attributes\n",
        "# all together. Here's a code fragment that sets up a table of token\n",
        "# attributes:\n",
        "\n",
        "import pandas as pd # Use a pandas DF\n",
        "\n",
        "# These will be out column names\n",
        "cols = (\"text\", \"lemma_\",\"is_punct\", \"is_stop\", \"is_alpha\",\"is_space\",\"lower_\")\n",
        "\n",
        "rows = [] # A blank list to hold the rows\n",
        "\n",
        "for t in doc: # Iterate through the tokens - will work for any length document\n",
        "    # build the next row\n",
        "    row = [t.text, t.lemma_,  t.is_punct,  t.is_stop,  t.is_alpha,  t.is_space,  t.lower_]\n",
        "    rows.append(row) # Append the row to the existing rows\n",
        "\n",
        "# Create the pandas data frame from the column names and the list of rows\n",
        "attri_pdf = pd.DataFrame(rows, columns=cols)\n",
        "\n",
        "attri_pdf # Gives a preview, but may not show all rows"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           text       lemma_  is_punct  is_stop  is_alpha  is_space  \\\n",
              "0            An           an     False     True      True     False   \n",
              "1   information  information     False    False      True     False   \n",
              "2     retrieval    retrieval     False    False      True     False   \n",
              "3     technique    technique     False    False      True     False   \n",
              "4         using          use     False     True      True     False   \n",
              "..          ...          ...       ...      ...       ...       ...   \n",
              "62     indexing     indexing     False    False      True     False   \n",
              "63            (            (      True    False     False     False   \n",
              "64          LSI          LSI     False    False      True     False   \n",
              "65            )            )      True    False     False     False   \n",
              "66            .            .      True    False     False     False   \n",
              "\n",
              "         lower_  \n",
              "0            an  \n",
              "1   information  \n",
              "2     retrieval  \n",
              "3     technique  \n",
              "4         using  \n",
              "..          ...  \n",
              "62     indexing  \n",
              "63            (  \n",
              "64          lsi  \n",
              "65            )  \n",
              "66            .  \n",
              "\n",
              "[67 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f9f76da-7048-4568-98d6-32a01b055652\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lemma_</th>\n",
              "      <th>is_punct</th>\n",
              "      <th>is_stop</th>\n",
              "      <th>is_alpha</th>\n",
              "      <th>is_space</th>\n",
              "      <th>lower_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>An</td>\n",
              "      <td>an</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>an</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>information</td>\n",
              "      <td>information</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>information</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>retrieval</td>\n",
              "      <td>retrieval</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>technique</td>\n",
              "      <td>technique</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>technique</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>using</td>\n",
              "      <td>use</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>using</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>indexing</td>\n",
              "      <td>indexing</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>indexing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>(</td>\n",
              "      <td>(</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>(</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>LSI</td>\n",
              "      <td>LSI</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>lsi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>)</td>\n",
              "      <td>)</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f9f76da-7048-4568-98d6-32a01b055652')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f9f76da-7048-4568-98d6-32a01b055652 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f9f76da-7048-4568-98d6-32a01b055652');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-294334c8-9a49-48aa-a370-d9232af1bdef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-294334c8-9a49-48aa-a370-d9232af1bdef')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-294334c8-9a49-48aa-a370-d9232af1bdef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACTokpuocVZG"
      },
      "source": [
        "In previous weeks we have considered stop words and why in some cases it makes sense to remove them from the token stream. Let's examine spaCy's stop word list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmEFYVF_cVZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c47b4b-191e-4599-b799-6fc9ce5e2414"
      },
      "source": [
        "import spacy\n",
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "len(spacy_stopwords)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYfeBc3ccVZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c292df-5bef-4b8f-e487-559d565fa9b9"
      },
      "source": [
        "list(spacy_stopwords)[:8]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['anyhow',\n",
              " 'if',\n",
              " 'along',\n",
              " 'latterly',\n",
              " 'whenever',\n",
              " 'towards',\n",
              " 'beyond',\n",
              " 'eleven']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5x3AkUho6QE"
      },
      "source": [
        "While it is good to know what is on the stop list, we don't usually need it as spaCy has already tagged each token with an attribute showing whether that token is a stop word. Let's process another piece of text from Wikipedia to focus on the stop words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOtvuhEvcVZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2956f84e-da6a-4f39-9aba-5850902d7419"
      },
      "source": [
        "text = \"\"\"In natural language processing, the Latent Dirichlet Allocation (LDA)\n",
        "is a generative statistical model that allows sets of observations to be\n",
        "explained by unobserved groups that explain why some parts of the data are\n",
        "similar. For example, if observations are words collected into documents,\n",
        "it posits that each document is a mixture of a small number of topics and that\n",
        "each word's presence is attributable to one of the document's topics. LDA is\n",
        "an example of a topic model and belongs to the machine learning field and in\n",
        "a wider sense to the artificial intelligence field.\"\"\"\n",
        "\n",
        "doc = nlp(text)\n",
        "type(doc), len(doc)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(spacy.tokens.doc.Doc, 113)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb00Z7RFpZG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ecf3ea-6768-4529-c689-80012ad25b70"
      },
      "source": [
        "# Display the tokens that are stop words:\n",
        "print([token for token in doc if token.is_stop])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[In, the, is, a, that, of, to, be, by, that, why, some, of, the, are, For, if, are, into, it, that, each, is, a, of, a, of, and, that, each, 's, is, to, one, of, the, 's, is, an, of, a, and, to, the, and, in, a, to, the]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ny2AwIJcVZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de907686-f432-43f8-8360-d862d5c40166"
      },
      "source": [
        "# Make a list of the tokens that are not stop-words\n",
        "no_stops = [token for token in doc if not token.is_stop]\n",
        "type(no_stops), len(no_stops)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V09k1Ar0ZZQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d738d235-b324-4457-e7cc-2cc71913e7ee"
      },
      "source": [
        "# Use slicing to view the first few non-stop words.\n",
        "no_stops[0:12]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[natural,\n",
              " language,\n",
              " processing,\n",
              " ,,\n",
              " Latent,\n",
              " Dirichlet,\n",
              " Allocation,\n",
              " (,\n",
              " LDA,\n",
              " ),\n",
              " ,\n",
              " generative]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCBYMAEgp4Z0"
      },
      "source": [
        "In some applications we may have uses for the punctuation tokens, but it is also good to know how to remove them. Conveniently, spaCy has also tagged every token with an indicator of whether it is punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_F-0mSaalU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3eb73a-b6dd-45b6-b7d0-0b767e81cb61"
      },
      "source": [
        "# Also remove punctuation tokens\n",
        "no_stops_or_punct = [token for token in no_stops if not token.is_punct]\n",
        "type(no_stops_or_punct[0]), len(no_stops_or_punct)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(spacy.tokens.token.Token, 56)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWC-WDivmMIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f28ede5-53f9-4fed-9084-5a627ac60736"
      },
      "source": [
        "# Use slicing to view the first few non-stop, non-punct words.\n",
        "no_stops_or_punct[0:10]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[natural,\n",
              " language,\n",
              " processing,\n",
              " Latent,\n",
              " Dirichlet,\n",
              " Allocation,\n",
              " LDA,\n",
              " ,\n",
              " generative,\n",
              " statistical]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CkpzGjVcVZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3177fd-7397-4363-8e44-1c41bbc54429"
      },
      "source": [
        "# Another attribute on a token contains the lowercase version\n",
        "# of the token. Why does this attribute end with an underscore?\n",
        "lowercased = [ token.lower_ for token in no_stops_or_punct]\n",
        "lowercased[0:9]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'latent',\n",
              " 'dirichlet',\n",
              " 'allocation',\n",
              " 'lda',\n",
              " '\\n',\n",
              " 'generative']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVdSnFcvqiZy"
      },
      "source": [
        "When we called nlp() on the text object and created the tokens, spaCy also automatically guessed at the lemma for each token and stuck that in as an attribute.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH48zQg4bYNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1104778f-e01d-4472-8cc5-8c9134f88b39"
      },
      "source": [
        "# Make an additional list of lemma tokens\n",
        "lemma_list = [token.lemma_ for token in no_stops_or_punct]\n",
        "type(lemma_list[0]), len(set(lemma_list))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(str, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHc9jkwLdTrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5182d5b-b29a-4528-eb0a-71a1d573eb28"
      },
      "source": [
        "# The output above suggests that some lemmas appear in the token\n",
        "# list more than one time. Use Counter from the collections package\n",
        "# to count instances of lemmas.\n",
        "from collections import Counter\n",
        "\n",
        "# 6.7: Instantiate a counter object with Counter(lemma_list). Assign this\n",
        "# to a new variable such as wc_lemmas\n",
        "\n",
        "wc_lemmas = Counter(lemma_list)\n",
        "\n",
        "# 6.8: Display the frequency counts of the five most common lemmas. Hint:\n",
        "# a Counter has a bound method called most_common() that takes one\n",
        "# argument called \"n\"\n",
        "\n",
        "most_common_lemmas = wc_lemmas.most_common(5)\n",
        "print(most_common_lemmas)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 7), ('document', 3), ('topic', 3), ('LDA', 2), ('model', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.9: Grab a new long string from Wikipedia or another source\n",
        "#      and remove stop words and punctuation, then lemmatize and\n",
        "#      count the frequencies of the top five lemmas.\n",
        "\n",
        "text = \"\"\"View of the Tower of Hercules near the center of A Coruña, Galicia, north-western\n",
        "          coast of Spain. The 55 metres (180 ft) hight tower, an ancient Roman lighthouse, is\n",
        "          the oldest (almost 1900 years) Roman lighthouse in use today and the second tallest\n",
        "          lighthouse in Spain (after the Faro de Chipiona).\n",
        "          The lighthouse was rehabilitated in 1791 and is a UNESCO World Heritage Site since 2009.\"\"\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "no_stops = [token for token in doc if not token.is_stop]\n",
        "no_stops_or_punct = [token for token in no_stops if not token.is_punct]\n",
        "lowercased = [ token.lower_ for token in no_stops_or_punct]\n",
        "lemma_list = [token.lemma_ for token in no_stops_or_punct]\n",
        "wc_lemmas = Counter(lemma_list)\n",
        "most_common_lemmas = wc_lemmas.most_common(5)\n",
        "print(most_common_lemmas)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x790YAn2on1u",
        "outputId": "f1c5b9e4-93dc-442d-a5ee-905a1f5eca3f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n          ', 4), ('lighthouse', 4), ('Spain', 2), ('roman', 2), ('view', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAnZFrsRcVZJ"
      },
      "source": [
        "# Sentence Segmentation\n",
        "\n",
        "The spaCy doc object contains an element called \"sents\" that records the beginning and ending position (counting by tokens) of each sentence in the document. As you may have discussed in class, finding sentence boundaries requires a substantial amount of algorithmic complexity, because the ending punctuation in strings such as U.S. or etc. may or may not indicate a sentence boundary. There are four strategies for sentence boundary detection in spaCy: dependency parser (default), statistical segmenter, rule-based segmenter, or custom function. Let's tokenize a fragment of Wikipedia text using the default (dependency parser) and then examine the resulting sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-YbifqjcVZJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85e1dc33-e4b9-4091-cc59-f4ad2cc85584"
      },
      "source": [
        "text = \"\"\"Sentence boundary disambiguation (SBD), also known as sentence breaking, sentence boundary detection, and sentence segmentation, is the problem in natural language processing of deciding where sentences begin and end. Natural language processing tools often require their input to be divided into sentences; however, sentence boundary identification can be challenging due to the potential ambiguity of punctuation marks. In written English, a period may indicate the end of a sentence, or may denote an abbreviation, a decimal point, an ellipsis, or an email address, among other possibilities. About 47% of the periods in the Wall Street Journal corpus denote abbreviations.[1] Question marks and exclamation marks can be similarly ambiguous due to use in emoticons, computer code, and slang.\"\"\"\n",
        "text[-26:] # Show the end of the string\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' computer code, and slang.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng04k0RNcVZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0e0867-0899-4583-f1c0-bf9fff41718f"
      },
      "source": [
        "doc = nlp(text)\n",
        "type(doc.sents)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generator"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM_0KnK2vYow"
      },
      "source": [
        "In Python, a generator is a special kind of iterator function that creates the requested elements on demand and \"on the fly.\" This is a helpful approach when working with large sets of data elements that it would be challenging to represent in memory all at once.  So doc.sents is a generator object, which means we can iterate through it's elements to find what we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMmFpAT3cVZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "368fa4fe-25f8-4274-b4cc-6cd6ab714fa2"
      },
      "source": [
        "for sent in doc.sents:\n",
        "    print(\"start_pos={}, end_pos={}, text:{}\".format(sent.start, sent.end, sent.text))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_pos=0, end_pos=36, text:Sentence boundary disambiguation (SBD), also known as sentence breaking, sentence boundary detection, and sentence segmentation, is the problem in natural language processing of deciding where sentences begin and end.\n",
            "start_pos=36, end_pos=67, text:Natural language processing tools often require their input to be divided into sentences; however, sentence boundary identification can be challenging due to the potential ambiguity of punctuation marks.\n",
            "start_pos=67, end_pos=103, text:In written English, a period may indicate the end of a sentence, or may denote an abbreviation, a decimal point, an ellipsis, or an email address, among other possibilities.\n",
            "start_pos=103, end_pos=139, text:About 47% of the periods in the Wall Street Journal corpus denote abbreviations.[1] Question marks and exclamation marks can be similarly ambiguous due to use in emoticons, computer code, and slang.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3SWM52scVZK"
      },
      "source": [
        "# Part of Speech Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bIdEjLocVZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1cacd9-da65-4ad4-c163-d0630153f52f"
      },
      "source": [
        "doc = nlp(\"I was reading an article about Berkeley Avenue in Reading, which was closed due to a police investigation.\")\n",
        "type(doc), len(doc)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(spacy.tokens.doc.Doc, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbZPfIWacVZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7317211f-595f-483f-b903-18a3783b9855"
      },
      "source": [
        "from tabulate import tabulate # To make a neat table\n",
        "\n",
        "tabdata = [ (token.text, token.tag_, token.pos_, spacy.explain(token.tag_)) for token in doc]\n",
        "\n",
        "print(tabulate(tabdata,  headers=[\"Token\", \"Token Tag\", \"POS\", \"Explanation\"]))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token          Token Tag    POS    Explanation\n",
            "-------------  -----------  -----  -----------------------------------------\n",
            "I              PRP          PRON   pronoun, personal\n",
            "was            VBD          AUX    verb, past tense\n",
            "reading        VBG          VERB   verb, gerund or present participle\n",
            "an             DT           DET    determiner\n",
            "article        NN           NOUN   noun, singular or mass\n",
            "about          IN           ADP    conjunction, subordinating or preposition\n",
            "Berkeley       NNP          PROPN  noun, proper singular\n",
            "Avenue         NNP          PROPN  noun, proper singular\n",
            "in             IN           ADP    conjunction, subordinating or preposition\n",
            "Reading        NNP          PROPN  noun, proper singular\n",
            ",              ,            PUNCT  punctuation mark, comma\n",
            "which          WDT          PRON   wh-determiner\n",
            "was            VBD          AUX    verb, past tense\n",
            "closed         VBN          VERB   verb, past participle\n",
            "due            IN           ADP    conjunction, subordinating or preposition\n",
            "to             IN           ADP    conjunction, subordinating or preposition\n",
            "a              DT           DET    determiner\n",
            "police         NN           NOUN   noun, singular or mass\n",
            "investigation  NN           NOUN   noun, singular or mass\n",
            ".              .            PUNCT  punctuation mark, sentence closer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "497I80HCoK-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1f3a50-aac6-40f9-8a3f-6d125f09631b"
      },
      "source": [
        "# Make a list of tokens for all of the proper nouns\n",
        "propnlist = [token for token in doc if token.pos_ == \"PROPN\"]\n",
        "\n",
        "[ (token, token.is_ascii, token.is_title) for token in propnlist]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Berkeley, True, True), (Avenue, True, True), (Reading, True, True)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hck-VPXBqtYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faacfa81-dc76-4125-f5a9-b9256fffe72b"
      },
      "source": [
        "# Find another sentence that includes a place name. Tokenize it,\n",
        "# display the POS tags, and excerpt the proper noun(s).\n",
        "\n",
        "# 6.10: Create a new text object for tokenizing.\n",
        "\n",
        "text = \"\"\"View of the Tower of Hercules near the center of A Coruña, Galicia, north-western\n",
        "          coast of Spain. The 55 metres (180 ft) hight tower, an ancient Roman lighthouse, is\n",
        "          the oldest (almost 1900 years) Roman lighthouse in use today and the second tallest\n",
        "          lighthouse in Spain (after the Faro de Chipiona).\n",
        "          The lighthouse was rehabilitated in 1791 and is a UNESCO World Heritage Site since 2009.\"\"\"\n",
        "\n",
        "\n",
        "# 6.11: Tokenize the text object.\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "# 6.12: Display the POS tags for all tokens.\n",
        "\n",
        "tabdata = [ (token.text, token.tag_, token.pos_, spacy.explain(token.tag_)) for token in doc]\n",
        "print(tabulate(tabdata,  headers=[\"Token\", \"Token Tag\", \"POS\", \"Explanation\"]))\n",
        "\n",
        "# 6.13: Extract the proper nouns and display them.\n",
        "\n",
        "propnlist = [token for token in doc if token.pos_ == \"PROPN\"]\n",
        "\n",
        "[ token for token in propnlist]\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token          Token Tag    POS    Explanation\n",
            "-------------  -----------  -----  --------------------------------------------------\n",
            "View           NN           NOUN   noun, singular or mass\n",
            "of             IN           ADP    conjunction, subordinating or preposition\n",
            "the            DT           DET    determiner\n",
            "Tower          NNP          PROPN  noun, proper singular\n",
            "of             IN           ADP    conjunction, subordinating or preposition\n",
            "Hercules       NNP          PROPN  noun, proper singular\n",
            "near           IN           ADP    conjunction, subordinating or preposition\n",
            "the            DT           DET    determiner\n",
            "center         NN           NOUN   noun, singular or mass\n",
            "of             IN           ADP    conjunction, subordinating or preposition\n",
            "A              DT           DET    determiner\n",
            "Coruña         NNP          PROPN  noun, proper singular\n",
            ",              ,            PUNCT  punctuation mark, comma\n",
            "Galicia        NNP          PROPN  noun, proper singular\n",
            ",              ,            PUNCT  punctuation mark, comma\n",
            "north          NN           NOUN   noun, singular or mass\n",
            "-              HYPH         PUNCT  punctuation mark, hyphen\n",
            "western        JJ           ADJ    adjective (English), other noun-modifier (Chinese)\n",
            "               _SP          SPACE  whitespace\n",
            "coast          NN           NOUN   noun, singular or mass\n",
            "of             IN           ADP    conjunction, subordinating or preposition\n",
            "Spain          NNP          PROPN  noun, proper singular\n",
            ".              .            PUNCT  punctuation mark, sentence closer\n",
            "The            DT           DET    determiner\n",
            "55             CD           NUM    cardinal number\n",
            "metres         NNS          NOUN   noun, plural\n",
            "(              -LRB-        PUNCT  left round bracket\n",
            "180            CD           NUM    cardinal number\n",
            "ft             NN           NOUN   noun, singular or mass\n",
            ")              -RRB-        PUNCT  right round bracket\n",
            "hight          NN           NOUN   noun, singular or mass\n",
            "tower          NN           NOUN   noun, singular or mass\n",
            ",              ,            PUNCT  punctuation mark, comma\n",
            "an             DT           DET    determiner\n",
            "ancient        JJ           ADJ    adjective (English), other noun-modifier (Chinese)\n",
            "Roman          JJ           ADJ    adjective (English), other noun-modifier (Chinese)\n",
            "lighthouse     NN           NOUN   noun, singular or mass\n",
            ",              ,            PUNCT  punctuation mark, comma\n",
            "is             VBZ          AUX    verb, 3rd person singular present\n",
            "               _SP          SPACE  whitespace\n",
            "the            DT           DET    determiner\n",
            "oldest         JJS          ADJ    adjective, superlative\n",
            "(              -LRB-        PUNCT  left round bracket\n",
            "almost         RB           ADV    adverb\n",
            "1900           CD           NUM    cardinal number\n",
            "years          NNS          NOUN   noun, plural\n",
            ")              -RRB-        PUNCT  right round bracket\n",
            "Roman          JJ           ADJ    adjective (English), other noun-modifier (Chinese)\n",
            "lighthouse     NN           NOUN   noun, singular or mass\n",
            "in             IN           ADP    conjunction, subordinating or preposition\n",
            "use            NN           NOUN   noun, singular or mass\n",
            "today          NN           NOUN   noun, singular or mass\n",
            "and            CC           CCONJ  conjunction, coordinating\n",
            "the            DT           DET    determiner\n",
            "second         JJ           ADJ    adjective (English), other noun-modifier (Chinese)\n",
            "tallest        JJS          ADJ    adjective, superlative\n",
            "               _SP          SPACE  whitespace\n",
            "lighthouse     NN           NOUN   noun, singular or mass\n",
            "in             IN           ADP    conjunction, subordinating or preposition\n",
            "Spain          NNP          PROPN  noun, proper singular\n",
            "(              -LRB-        PUNCT  left round bracket\n",
            "after          IN           ADP    conjunction, subordinating or preposition\n",
            "the            DT           DET    determiner\n",
            "Faro           NNP          PROPN  noun, proper singular\n",
            "de             FW           X      foreign word\n",
            "Chipiona       NNP          PROPN  noun, proper singular\n",
            ")              -RRB-        PUNCT  right round bracket\n",
            ".              .            PUNCT  punctuation mark, sentence closer\n",
            "               _SP          SPACE  whitespace\n",
            "The            DT           DET    determiner\n",
            "lighthouse     NN           NOUN   noun, singular or mass\n",
            "was            VBD          AUX    verb, past tense\n",
            "rehabilitated  VBN          VERB   verb, past participle\n",
            "in             IN           ADP    conjunction, subordinating or preposition\n",
            "1791           CD           NUM    cardinal number\n",
            "and            CC           CCONJ  conjunction, coordinating\n",
            "is             VBZ          AUX    verb, 3rd person singular present\n",
            "a              DT           DET    determiner\n",
            "UNESCO         NNP          PROPN  noun, proper singular\n",
            "World          NNP          PROPN  noun, proper singular\n",
            "Heritage       NNP          PROPN  noun, proper singular\n",
            "Site           NNP          PROPN  noun, proper singular\n",
            "since          IN           SCONJ  conjunction, subordinating or preposition\n",
            "2009           CD           NUM    cardinal number\n",
            ".              .            PUNCT  punctuation mark, sentence closer\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tower,\n",
              " Hercules,\n",
              " Coruña,\n",
              " Galicia,\n",
              " Spain,\n",
              " Spain,\n",
              " Faro,\n",
              " Chipiona,\n",
              " UNESCO,\n",
              " World,\n",
              " Heritage,\n",
              " Site]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KXiIBy4cVZK"
      },
      "source": [
        "# Dependency Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxQ23QB3cVZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6d1fa5-3271-42e3-fc49-53422c6553e2"
      },
      "source": [
        "# The part of speech tags displayed above were determined after a thorough\n",
        "# parsing of the dependency structure of the sentence. Let's take a closer\n",
        "# look at the dependency structure:\n",
        "from tabulate import tabulate # To make a neat table\n",
        "\n",
        "tabdata = [ (token.text, token.tag_, token.dep_, token.head.text, token.head.tag_) for token in doc]\n",
        "\n",
        "print(tabulate(tabdata,  headers=[\"Token\", \"Token POS\", \"Dependency\", \"Head Token\", \"Head POS\"]))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token          Token POS    Dependency    Head Token     Head POS\n",
            "-------------  -----------  ------------  -------------  ----------\n",
            "View           NN           ROOT          View           NN\n",
            "of             IN           prep          View           NN\n",
            "the            DT           det           Tower          NNP\n",
            "Tower          NNP          pobj          of             IN\n",
            "of             IN           prep          Tower          NNP\n",
            "Hercules       NNP          pobj          of             IN\n",
            "near           IN           prep          View           NN\n",
            "the            DT           det           center         NN\n",
            "center         NN           pobj          near           IN\n",
            "of             IN           prep          center         NN\n",
            "A              DT           det           Galicia        NNP\n",
            "Coruña         NNP          nmod          Galicia        NNP\n",
            ",              ,            punct         Coruña         NNP\n",
            "Galicia        NNP          pobj          of             IN\n",
            ",              ,            punct         Galicia        NNP\n",
            "north          NN           compound      western        JJ\n",
            "-              HYPH         punct         western        JJ\n",
            "western        JJ           amod          coast          NN\n",
            "               _SP          dep           western        JJ\n",
            "coast          NN           appos         Galicia        NNP\n",
            "of             IN           prep          coast          NN\n",
            "Spain          NNP          pobj          of             IN\n",
            ".              .            punct         View           NN\n",
            "The            DT           det           metres         NNS\n",
            "55             CD           nummod        metres         NNS\n",
            "metres         NNS          nsubj         is             VBZ\n",
            "(              -LRB-        punct         metres         NNS\n",
            "180            CD           nummod        tower          NN\n",
            "ft             NN           compound      tower          NN\n",
            ")              -RRB-        punct         tower          NN\n",
            "hight          NN           compound      tower          NN\n",
            "tower          NN           nsubj         is             VBZ\n",
            ",              ,            punct         tower          NN\n",
            "an             DT           det           lighthouse     NN\n",
            "ancient        JJ           amod          lighthouse     NN\n",
            "Roman          JJ           amod          lighthouse     NN\n",
            "lighthouse     NN           appos         tower          NN\n",
            ",              ,            punct         tower          NN\n",
            "is             VBZ          ROOT          is             VBZ\n",
            "               _SP          dep           is             VBZ\n",
            "the            DT           det           years          NNS\n",
            "oldest         JJS          amod          years          NNS\n",
            "(              -LRB-        punct         years          NNS\n",
            "almost         RB           advmod        1900           CD\n",
            "1900           CD           nummod        years          NNS\n",
            "years          NNS          attr          is             VBZ\n",
            ")              -RRB-        punct         is             VBZ\n",
            "Roman          JJ           amod          lighthouse     NN\n",
            "lighthouse     NN           ROOT          lighthouse     NN\n",
            "in             IN           prep          lighthouse     NN\n",
            "use            NN           pobj          in             IN\n",
            "today          NN           npadvmod      lighthouse     NN\n",
            "and            CC           cc            today          NN\n",
            "the            DT           det           lighthouse     NN\n",
            "second         JJ           amod          lighthouse     NN\n",
            "tallest        JJS          amod          lighthouse     NN\n",
            "               _SP          dep           tallest        JJS\n",
            "lighthouse     NN           conj          today          NN\n",
            "in             IN           prep          lighthouse     NN\n",
            "Spain          NNP          pobj          in             IN\n",
            "(              -LRB-        punct         lighthouse     NN\n",
            "after          IN           prep          lighthouse     NN\n",
            "the            DT           det           Chipiona       NNP\n",
            "Faro           NNP          compound      Chipiona       NNP\n",
            "de             FW           compound      Chipiona       NNP\n",
            "Chipiona       NNP          pobj          after          IN\n",
            ")              -RRB-        punct         lighthouse     NN\n",
            ".              .            punct         lighthouse     NN\n",
            "               _SP          dep           .              .\n",
            "The            DT           det           lighthouse     NN\n",
            "lighthouse     NN           nsubjpass     rehabilitated  VBN\n",
            "was            VBD          auxpass       rehabilitated  VBN\n",
            "rehabilitated  VBN          ROOT          rehabilitated  VBN\n",
            "in             IN           prep          rehabilitated  VBN\n",
            "1791           CD           pobj          in             IN\n",
            "and            CC           cc            rehabilitated  VBN\n",
            "is             VBZ          conj          rehabilitated  VBN\n",
            "a              DT           det           Site           NNP\n",
            "UNESCO         NNP          compound      Site           NNP\n",
            "World          NNP          compound      Heritage       NNP\n",
            "Heritage       NNP          compound      Site           NNP\n",
            "Site           NNP          attr          is             VBZ\n",
            "since          IN           prep          is             VBZ\n",
            "2009           CD           pobj          since          IN\n",
            ".              .            punct         rehabilitated  VBN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PszlZv3HnG6"
      },
      "source": [
        "Take a close look at the output just above. For each token in the sentence, the text of the token is shown along with its part of speech. Then the dependency relation is shown. For example, the first token, \"I\", is the noun/subject of the sentence and is therefore dependent on the main verb, \"reading\", which is the gerund form of the verb to read.\n",
        "\n",
        "Take the time to examine each row of the output and make sure you understand the dependency relation that is being documented. And remember that spaCy's ability to diagram the relations in this way works because of the language model we originally loaded: \"en_core_web_sm\". Also important: The default sentence segmentation that we examined in a previous block works because spaCy's dependency parser accounts for all of the elements in a sentence, and therefore \"knows\" when the period character is closing a sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a_nCqwbJ3sV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd884ce-1f08-4018-dbfa-7e68b0d376b6"
      },
      "source": [
        "# Grab another sentence from the web, but this time, cut off the sentence\n",
        "# before the end so that some key grammatical element is missing. Do paste\n",
        "# a period on the end, though, just to see if you can confuse spaCy.\n",
        "\n",
        "# 6.14: Cut and paste part of a sentence from the web into a text variable.\n",
        "\n",
        "text = \"\"\"The planet Venus has been used as a setting in fiction since before the 19th century.\n",
        "          Its impenetrable cloud cover gave writers free rein to speculate on conditions at Venus's surface,\n",
        "          which was often depicted as warmer than Earth's but habitable. Images of a lush, verdant paradise.\"\"\"\n",
        "\n",
        "# 6.15: Tokenize the sentence.\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "# 6.16: Generate a table showing the dependency relations in the sentence.\n",
        "\n",
        "tabdata = [ (token.text, token.tag_, token.dep_, token.head.text, token.head.tag_) for token in doc]\n",
        "\n",
        "print(tabulate(tabdata,  headers=[\"Token\", \"Token POS\", \"Dependency\", \"Head Token\", \"Head POS\"]))\n",
        "\n",
        "# 6.17: Add a comment to document any mistakes that spaCy made.\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token         Token POS    Dependency    Head Token    Head POS\n",
            "------------  -----------  ------------  ------------  ----------\n",
            "The           DT           det           Venus         NNP\n",
            "planet        NN           compound      Venus         NNP\n",
            "Venus         NNP          nsubjpass     used          VBN\n",
            "has           VBZ          aux           used          VBN\n",
            "been          VBN          auxpass       used          VBN\n",
            "used          VBN          ROOT          used          VBN\n",
            "as            IN           prep          used          VBN\n",
            "a             DT           det           setting       NN\n",
            "setting       NN           pobj          as            IN\n",
            "in            IN           prep          setting       NN\n",
            "fiction       NN           pobj          in            IN\n",
            "since         IN           prep          used          VBN\n",
            "before        IN           prep          since         IN\n",
            "the           DT           det           century       NN\n",
            "19th          JJ           amod          century       NN\n",
            "century       NN           pobj          before        IN\n",
            ".             .            punct         used          VBN\n",
            "              _SP          dep           .             .\n",
            "Its           PRP$         poss          cover         NN\n",
            "impenetrable  JJ           amod          cover         NN\n",
            "cloud         NN           compound      cover         NN\n",
            "cover         NN           nsubj         gave          VBD\n",
            "gave          VBD          ROOT          gave          VBD\n",
            "writers       NNS          dative        gave          VBD\n",
            "free          JJ           amod          rein          NN\n",
            "rein          NN           dobj          gave          VBD\n",
            "to            TO           aux           speculate     VB\n",
            "speculate     VB           relcl         rein          NN\n",
            "on            IN           prep          speculate     VB\n",
            "conditions    NNS          pobj          on            IN\n",
            "at            IN           prep          conditions    NNS\n",
            "Venus         NNP          poss          surface       NN\n",
            "'s            POS          case          Venus         NNP\n",
            "surface       NN           pobj          at            IN\n",
            ",             ,            punct         surface       NN\n",
            "              _SP          dep           ,             ,\n",
            "which         WDT          nsubjpass     depicted      VBN\n",
            "was           VBD          auxpass       depicted      VBN\n",
            "often         RB           advmod        depicted      VBN\n",
            "depicted      VBN          relcl         surface       NN\n",
            "as            IN           prep          depicted      VBN\n",
            "warmer        JJR          pobj          as            IN\n",
            "than          IN           prep          warmer        JJR\n",
            "Earth         NNP          pobj          than          IN\n",
            "'s            POS          case          Earth         NNP\n",
            "but           CC           cc            warmer        JJR\n",
            "habitable     JJ           conj          warmer        JJR\n",
            ".             .            punct         gave          VBD\n",
            "Images        NNS          ROOT          Images        NNS\n",
            "of            IN           prep          Images        NNS\n",
            "a             DT           det           paradise      NN\n",
            "lush          JJ           amod          paradise      NN\n",
            ",             ,            punct         paradise      NN\n",
            "verdant       JJ           amod          paradise      NN\n",
            "paradise      NN           pobj          of            IN\n",
            ".             .            punct         Images        NNS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1pOdKqdIcVZK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "5a70de02-c0e5-4ff3-9b37-2783f64fd6d7"
      },
      "source": [
        "# There is a graphical display module for\n",
        "# spaCy that supports drawing a figure of the dependency relations.\n",
        "from spacy import displacy\n",
        "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"416c3d9ce9ba431da29ca861b9a287e5-0\" class=\"displacy\" width=\"4640\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">planet</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">Venus</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">has</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">been</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">used</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">as</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">setting</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">fiction</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">since</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">SCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">before</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1220\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1220\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1310\">19th</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1310\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">century.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">PUNCT</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1490\">\n",
              "          </tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1490\">SPACE</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1580\">Its</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1580\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1670\">impenetrable</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1670\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1760\">cloud</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1760\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">cover</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1940\">gave</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1940\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2030\">writers</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2030\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2120\">free</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2120\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2210\">rein</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2210\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2300\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2300\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2390\">speculate</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2390\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2480\">on</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2480\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2570\">conditions</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2570\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2660\">at</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2660\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2750\">Venus</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2840\">'s</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2840\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2930\">surface,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2930\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3020\">\n",
              "          </tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3020\">SPACE</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3110\">which</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3110\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">was</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3290\">often</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3290\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3380\">depicted</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3380\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3470\">as</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3470\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3560\">warmer</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3560\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3650\">than</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3650\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3740\">Earth</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3740\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3830\">'s</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3830\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3920\">but</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3920\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4010\">habitable.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4010\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4100\">Images</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4190\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4190\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4280\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4280\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4370\">lush,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4370\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4460\">verdant</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4460\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4550\">paradise.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4550\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,92.0 220.0,92.0 220.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-1\" stroke-width=\"2px\" d=\"M160,182.0 C160,137.0 215.0,137.0 215.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M160,184.0 L152,172.0 168,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-2\" stroke-width=\"2px\" d=\"M250,182.0 C250,47.0 495.0,47.0 495.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M250,184.0 L242,172.0 258,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-3\" stroke-width=\"2px\" d=\"M340,182.0 C340,92.0 490.0,92.0 490.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M340,184.0 L332,172.0 348,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-4\" stroke-width=\"2px\" d=\"M430,182.0 C430,137.0 485.0,137.0 485.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M430,184.0 L422,172.0 438,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-5\" stroke-width=\"2px\" d=\"M520,182.0 C520,137.0 575.0,137.0 575.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M575.0,184.0 L583.0,172.0 567.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-6\" stroke-width=\"2px\" d=\"M700,182.0 C700,137.0 755.0,137.0 755.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M700,184.0 L692,172.0 708,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-7\" stroke-width=\"2px\" d=\"M610,182.0 C610,92.0 760.0,92.0 760.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M760.0,184.0 L768.0,172.0 752.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-8\" stroke-width=\"2px\" d=\"M790,182.0 C790,137.0 845.0,137.0 845.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M845.0,184.0 L853.0,172.0 837.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-9\" stroke-width=\"2px\" d=\"M880,182.0 C880,137.0 935.0,137.0 935.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M935.0,184.0 L943.0,172.0 927.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-10\" stroke-width=\"2px\" d=\"M520,182.0 C520,47.0 1035.0,47.0 1035.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1035.0,184.0 L1043.0,172.0 1027.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-11\" stroke-width=\"2px\" d=\"M1060,182.0 C1060,137.0 1115.0,137.0 1115.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1115.0,184.0 L1123.0,172.0 1107.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-12\" stroke-width=\"2px\" d=\"M1240,182.0 C1240,92.0 1390.0,92.0 1390.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1240,184.0 L1232,172.0 1248,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-13\" stroke-width=\"2px\" d=\"M1330,182.0 C1330,137.0 1385.0,137.0 1385.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1330,184.0 L1322,172.0 1338,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-14\" stroke-width=\"2px\" d=\"M520,182.0 C520,2.0 1400.0,2.0 1400.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1400.0,184.0 L1408.0,172.0 1392.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-15\" stroke-width=\"2px\" d=\"M1420,182.0 C1420,137.0 1475.0,137.0 1475.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1475.0,184.0 L1483.0,172.0 1467.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-16\" stroke-width=\"2px\" d=\"M1600,182.0 C1600,47.0 1845.0,47.0 1845.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1600,184.0 L1592,172.0 1608,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-17\" stroke-width=\"2px\" d=\"M1690,182.0 C1690,92.0 1840.0,92.0 1840.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1690,184.0 L1682,172.0 1698,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-18\" stroke-width=\"2px\" d=\"M1780,182.0 C1780,137.0 1835.0,137.0 1835.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1780,184.0 L1772,172.0 1788,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-19\" stroke-width=\"2px\" d=\"M1870,182.0 C1870,137.0 1925.0,137.0 1925.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1870,184.0 L1862,172.0 1878,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-20\" stroke-width=\"2px\" d=\"M1960,182.0 C1960,137.0 2015.0,137.0 2015.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dative</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2015.0,184.0 L2023.0,172.0 2007.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-21\" stroke-width=\"2px\" d=\"M2140,182.0 C2140,137.0 2195.0,137.0 2195.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2140,184.0 L2132,172.0 2148,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-22\" stroke-width=\"2px\" d=\"M1960,182.0 C1960,92.0 2200.0,92.0 2200.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2200.0,184.0 L2208.0,172.0 2192.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-23\" stroke-width=\"2px\" d=\"M2320,182.0 C2320,137.0 2375.0,137.0 2375.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2320,184.0 L2312,172.0 2328,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-24\" stroke-width=\"2px\" d=\"M2230,182.0 C2230,92.0 2380.0,92.0 2380.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2380.0,184.0 L2388.0,172.0 2372.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-25\" stroke-width=\"2px\" d=\"M2410,182.0 C2410,137.0 2465.0,137.0 2465.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2465.0,184.0 L2473.0,172.0 2457.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-26\" stroke-width=\"2px\" d=\"M2500,182.0 C2500,137.0 2555.0,137.0 2555.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2555.0,184.0 L2563.0,172.0 2547.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-27\" stroke-width=\"2px\" d=\"M2590,182.0 C2590,137.0 2645.0,137.0 2645.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2645.0,184.0 L2653.0,172.0 2637.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-28\" stroke-width=\"2px\" d=\"M2770,182.0 C2770,92.0 2920.0,92.0 2920.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2770,184.0 L2762,172.0 2778,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-29\" stroke-width=\"2px\" d=\"M2770,182.0 C2770,137.0 2825.0,137.0 2825.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2825.0,184.0 L2833.0,172.0 2817.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-30\" stroke-width=\"2px\" d=\"M2680,182.0 C2680,47.0 2925.0,47.0 2925.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2925.0,184.0 L2933.0,172.0 2917.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-31\" stroke-width=\"2px\" d=\"M2950,182.0 C2950,137.0 3005.0,137.0 3005.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3005.0,184.0 L3013.0,172.0 2997.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-32\" stroke-width=\"2px\" d=\"M3130,182.0 C3130,47.0 3375.0,47.0 3375.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3130,184.0 L3122,172.0 3138,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-33\" stroke-width=\"2px\" d=\"M3220,182.0 C3220,92.0 3370.0,92.0 3370.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-33\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3220,184.0 L3212,172.0 3228,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-34\" stroke-width=\"2px\" d=\"M3310,182.0 C3310,137.0 3365.0,137.0 3365.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-34\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3310,184.0 L3302,172.0 3318,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-35\" stroke-width=\"2px\" d=\"M2950,182.0 C2950,2.0 3380.0,2.0 3380.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-35\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3380.0,184.0 L3388.0,172.0 3372.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-36\" stroke-width=\"2px\" d=\"M3400,182.0 C3400,137.0 3455.0,137.0 3455.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-36\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3455.0,184.0 L3463.0,172.0 3447.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-37\" stroke-width=\"2px\" d=\"M3490,182.0 C3490,137.0 3545.0,137.0 3545.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-37\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3545.0,184.0 L3553.0,172.0 3537.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-38\" stroke-width=\"2px\" d=\"M3580,182.0 C3580,137.0 3635.0,137.0 3635.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-38\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3635.0,184.0 L3643.0,172.0 3627.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-39\" stroke-width=\"2px\" d=\"M3670,182.0 C3670,137.0 3725.0,137.0 3725.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-39\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3725.0,184.0 L3733.0,172.0 3717.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-40\" stroke-width=\"2px\" d=\"M3760,182.0 C3760,137.0 3815.0,137.0 3815.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-40\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3815.0,184.0 L3823.0,172.0 3807.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-41\" stroke-width=\"2px\" d=\"M3580,182.0 C3580,92.0 3910.0,92.0 3910.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-41\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3910.0,184.0 L3918.0,172.0 3902.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-42\" stroke-width=\"2px\" d=\"M3580,182.0 C3580,47.0 4005.0,47.0 4005.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-42\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4005.0,184.0 L4013.0,172.0 3997.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-43\" stroke-width=\"2px\" d=\"M4120,182.0 C4120,137.0 4175.0,137.0 4175.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-43\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4175.0,184.0 L4183.0,172.0 4167.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-44\" stroke-width=\"2px\" d=\"M4300,182.0 C4300,47.0 4545.0,47.0 4545.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-44\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4300,184.0 L4292,172.0 4308,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-45\" stroke-width=\"2px\" d=\"M4390,182.0 C4390,92.0 4540.0,92.0 4540.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-45\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4390,184.0 L4382,172.0 4398,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-46\" stroke-width=\"2px\" d=\"M4480,182.0 C4480,137.0 4535.0,137.0 4535.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-46\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4480,184.0 L4472,172.0 4488,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-416c3d9ce9ba431da29ca861b9a287e5-0-47\" stroke-width=\"2px\" d=\"M4210,182.0 C4210,2.0 4550.0,2.0 4550.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-416c3d9ce9ba431da29ca861b9a287e5-0-47\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4550.0,184.0 L4558.0,172.0 4542.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRBkxxybK9Rq"
      },
      "source": [
        "Now that you can see the dependency relations as a graph, do you notice any problems with the parsing? Did spaCy make any mistakes in connecting the various elements of the sentence?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl7OK86pcVZK"
      },
      "source": [
        "# Named Entity Recognition\n",
        "\n",
        "Whenever spaCy finds a token that looks like a proper noun, it tags it as a predicted named entity. \"Predicted,\" because each spaCy language model has a trained classifier that makes predictions of whether or not a token might be a named entity and also what type of entity it is (e.g., an organization, a country, or something else."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3YNPOeIcVZK"
      },
      "source": [
        "The IOB tagging method is a a straightforward way of notating the status of tokens. Tokens can have one of the following four statuses:\n",
        "\n",
        "| TAG | ID | DESCRIPTION                           |\n",
        "|:-----:|:----:|:---------------------------------------:|\n",
        "| I   | 1  | Token is inside an entity.            |\n",
        "| O   | 2  | Token is outside an entity.           |\n",
        "| B   | 3  | Token begins an entity.               |\n",
        "|     | 0  | No entity tag is set (missing value). |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFstPHGLcVZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab64a5e1-26a0-4861-f0ca-7bf265fa026b"
      },
      "source": [
        "text='''We’re bringing the celebration of Syracuse University’s 150 years of impact to Chicago'''\n",
        "doc = nlp(text)\n",
        "type(doc.ents)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNspkgjLLwwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53096524-6c44-4c5a-c58d-427f610c8c3b"
      },
      "source": [
        "# So the list of entities is a tuple, which means we should be able to slice it.\n",
        "doc.ents[0]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Syracuse University’s"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pkKIjUmycVZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0ed687-97f4-4244-a763-137c39a4e928"
      },
      "source": [
        "# We can iterate through all of the entities in the document.\n",
        "for ent in doc.ents:\n",
        "    print(\"{}, [{},{}), {}\".format(ent.text, ent.start_char, ent.end_char, ent.label_))\n",
        "\n",
        "    # For each entity, we can also access each entity as a span and\n",
        "    # iterate through its tokens\n",
        "    for token in ent.as_doc():\n",
        "        print(\"    {} {} {}\".format(token, token.ent_iob_, token.ent_type_))  #ent_iob_: IOB code of named entity tag. “B” means the token begins an entity, “I” means it is inside an entity, “O” means it is outside an entity, and \"\" means no entity tag is set."
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syracuse University’s, [34,55), ORG\n",
            "    Syracuse B ORG\n",
            "    University I ORG\n",
            "    ’s I ORG\n",
            "150 years, [56,65), DATE\n",
            "    150 B DATE\n",
            "    years I DATE\n",
            "Chicago, [79,86), GPE\n",
            "    Chicago B GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRQ1UByvcVZL"
      },
      "source": [
        "- __text__ gives the Unicode text representation of the entity.\n",
        "- __start_char__ denotes the character offset for the start of the entity.\n",
        "- __end_char__ denotes the character offset for the end of the entity.\n",
        "- __label___ gives the label of the entity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A62VfRrvcVZL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a55ef5e9-7320-40b1-c914-3f612e9a5854"
      },
      "source": [
        "# The displacy module can also provide a graphical view of the named entities:\n",
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">We’re bringing the celebration of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Syracuse University’s\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    150 years\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " of impact to \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Chicago\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLgDucPuPm97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "401fb532-f078-4415-e2c7-e0c0e2936204"
      },
      "source": [
        "# Now you copy and paste another sentence from the web that seems to contain\n",
        "# some named entities.\n",
        "\n",
        "# 6.18: Cut and paste part of a sentence from the web into a text variable.\n",
        "text = \"\"\"In the city of Paris, John and Mary visited the Louvre Museum, known for its stunning art collection.\n",
        "They admired the famous Mona Lisa painting, created by Leonardo da Vinci. After their museum tour, they enjoyed delicious\n",
        "croissants and coffee at a local cafe. Back in London, they took a ride on the iconic London Eye, a giant observation wheel\n",
        "on the South Bank of the River Thames. The view from the top was breathtaking, with Big Ben, Buckingham Palace, and the Shard in the distance.\n",
        "Their next stop was New York City, where they explored Central Park and Times Square. They caught a Broadway show and had dinner\n",
        "at a trendy restaurant in the heart of Manhattan.\n",
        "\"\"\"\n",
        "\n",
        "# 6.19: Tokenize the sentence.\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "# 6.20: Generate a displacy graphic with the named entities.\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In the city of \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Paris\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    John\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mary\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " visited \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the Louvre Museum\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", known for its stunning art collection. <br>They admired the famous \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mona Lisa\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " painting, created by \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Leonardo da Vinci\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ". After their museum tour, they enjoyed delicious <br>croissants and coffee at a local cafe. Back in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    London\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", they took a ride on the iconic \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    London Eye\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", a giant observation wheel <br>on \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the South Bank\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " of the River Thames. The view from the top was breathtaking, with \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Big Ben\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Buckingham Palace\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
              "</mark>\n",
              ", and the \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Shard\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              " in the distance. <br>Their next stop was \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    New York City\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", where they explored \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Central Park\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Times Square\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
              "</mark>\n",
              ". They caught a \n",
              "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Broadway\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
              "</mark>\n",
              " show and had dinner <br>at a trendy restaurant in the heart of \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Manhattan\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ".<br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwo7l9BrcVZO"
      },
      "source": [
        "# Optional Advanced Topic: Processing pipelines\n",
        "\n",
        "Throughout this lab, we have been calling a function that we often referred to as nlp(). After loading a spaCy language model such as en_core_web_sm, we instantiate a pipeline object to conduct all of the steps that we will routinely want to accomplish with a document.\n",
        "\n",
        "The spaCy pipeline can be modified to change the default components or to add new components. Here's a list of the default components from the spaCy documentation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsGcVmLrcVZP"
      },
      "source": [
        "<center><img style=\"text-align:center;\" src=\"img/pipeline.png\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMTUsVP5cVZP"
      },
      "source": [
        "| NAME      | COMPONENT         | CREATES                                             | DESCRIPTION                                      |\n",
        "|:-----------|:-------------------|:-----------------------------------------------------|:--------------------------------------------------|\n",
        "| tokenizer | Tokenizer         | Doc                                                 | Segment text into tokens.                        |\n",
        "| tagger    | Tagger            | Doc[i].tag                                          | Assign part-of-speech tags.                      |\n",
        "| parser    | DependencyParser  | Doc[i].head, Doc[i].dep, Doc.sents, Doc.noun_chunks | Assign dependency labels.                        |\n",
        "| ner       | EntityRecognizer  | Doc.ents, Doc[i].ent_iob, Doc[i].ent_type           | Detect and label named entities.                 |\n",
        "| textcat   | TextCategorizer   | Doc.cats                                            | Assign document labels.                          |\n",
        "| …         | custom components | `Doc._.xxx`, `Token._.xxx`, `Span._.xxx`                  | Assign custom attributes, methods or properties. |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BENxiG7XA3Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d50a24e-051a-46c8-f866-8db35c3a8559"
      },
      "source": [
        "# We can also examine the pipeline for an instantiated object like this:\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "nlp.pipeline"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x79a58f738c40>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x79a58d39e8c0>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x79a58ef736f0>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x79a58d1a7f80>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x79a58eee2bc0>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x79a58d3d3a00>)]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfta7uAsCxLv"
      },
      "source": [
        "You may notice in the list above that there is no tokenizer. In the spaCy pipeline model, it is assumed that tokenization was accomplished before pipeline processing begins. All pipeline elements receive a doc object, work on it and return a doc object. The tokenizer has a different kind of job becuase it receives a raw character string and returns a list of tokens. Thus, the language object has a different slot where the tokenizer is listed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi7w8BKTDF60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d8e649-71d6-496c-d1c1-9b9d33c3043b"
      },
      "source": [
        "nlp.tokenizer"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.tokenizer.Tokenizer at 0x79a58c2d09d0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMnmTk3qDTfS"
      },
      "source": [
        "The spaCy pipeline was designed to balance simplicity and computational effort. Simplicity is important for getting started quickly with a language processing tasks, so the default pipeline contains all the stuff that most people need to address a realistic task. But if a component is not needed, it can save a lot of compute time to take a task out of the pipeline. Take a look at this example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Z0Pp-4IB96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0387552f-cd4f-4026-899a-ee519aed1803"
      },
      "source": [
        "print(spacy.__version__) # Some version dependent stuff below"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm6zUJcuD00G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84842078-0bc1-4e3b-9ffa-231cb5832e23"
      },
      "source": [
        "# Let's skip the entity recognition and the dependency parsing\n",
        "nlp_simple = spacy.load(\"en_core_web_sm\", disable=[\"parser\",\"ner\"])\n",
        "# Note that in version 3 of spaCy, the disable argument has been\n",
        "# replaced by exclude. Version 3 also adds facilities for enabling\n",
        "# and disabling pipeline elements on the fly.\n",
        "\n",
        "print(nlp_simple.pipeline) # SHow the pipeline"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x79a58edda980>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x79a58edda9e0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x79a58f815180>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x79a58eeb8180>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYpDStT3IbTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7a8373-d196-4d76-9a2b-d8b11b829604"
      },
      "source": [
        "# Groucho Marx is an entity, but this pipeline doesn't detect it\n",
        "simple_doc = nlp_simple(\"Groucho Marx shot an elephant in his underpants.\")\n",
        "\n",
        "[ent for ent in simple_doc.ents]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Kj7lvGIgGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99fc946-04ce-4c39-f63e-9273baf98842"
      },
      "source": [
        "# And the pipeline did not do dependency parsing\n",
        "[token.dep_ for token in simple_doc]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '', '', '', '', '', '', '', '']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kl9G0O6cVZR"
      },
      "source": [
        "# Adding Custom Pipeline Components\n",
        "\n",
        "A component receives a Doc object and can modify it. By adding a component to the pipeline, you’ll get access to the Doc at any point during processing – instead of only being able to modify it afterwards. You can control the position of the new component in the pipeline with the last, first, before, and after arguments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIywcoktcVZR"
      },
      "source": [
        "| ARGUMENT | TYPE | DESCRIPTION                                          |\n",
        "|----------|------|------------------------------------------------------|\n",
        "| doc      | Doc  | The Doc object processed by the previous component.  |\n",
        "| RETURNS  | Doc  | The Doc object processed by this pipeline component. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTfX6L74cVZR"
      },
      "source": [
        "| ARGUMENT | TYPE    | DESCRIPTION                                                        |\n",
        "|----------|---------|--------------------------------------------------------------------|\n",
        "| last     | bool    | If set to True, component is added last in the pipeline (default). |\n",
        "| first    | bool    | If set to True, component is added first in the pipeline.          |\n",
        "| before   | unicode | String name of component to add the new component before.          |\n",
        "| after    | unicode | String name of component to add the new component after.           |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paTYGmxmcVZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0770e7bf-b9d6-40eb-d979-5373784246f4"
      },
      "source": [
        "import spacy\n",
        "from spacy.tokens import Doc, Span, Token\n",
        "import json\n",
        "\n",
        "# Instantiate a default pipeline\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process a sentence\n",
        "doc = nlp(\"This is a sentence.\")\n",
        "print(\"Before stopwords_removal, this doc is: {}\".format(doc))\n",
        "# See the result\n",
        "print(\"After stopwords_removal, this doc is: {}\".format([token.text for token in doc if not token.is_stop]))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before stopwords_removal, this doc is: This is a sentence.\n",
            "After stopwords_removal, this doc is: ['sentence', '.']\n"
          ]
        }
      ]
    }
  ]
}