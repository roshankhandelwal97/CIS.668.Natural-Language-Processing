{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiy-ZEZZlLlh"
      },
      "source": [
        "**IST664 - NLP Lab Week 1**\n",
        "\n",
        "Before getting started on this lab, make sure you have reviewed the introductory Python notebook (unless you are already experienced with Python). In this first section, we will use the Python “import” statement to load the NLTK package. This contains lots of text examples and unique capabilities for basic syntactic analysis of text. Whenever you see a code block containing only a comment (#) follow the instructions to add your own code.\n",
        "\n",
        "Among the loaded objects, NLTK includes 9 of the text examples available from the corpora package (only a small number of them!). It has used the variable names text1 through text9 for these examples, and already assigned them values. The variables sent1 through sent9 have been set to be a list of tokens of the first sentence of each text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tVAmC7V6Xf9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dada445-022b-4ca7-fb09-9e386f299d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/genesis.zip.\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/webtext.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "# IST664 - NLP Lab Week 1\n",
        "# This notebook has small examples that are meant to be run step by step.\n",
        "\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('treebank')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "from nltk.book import * # This may throw errors, looking for other downloads\n",
        "# Just add them into the list of downloads above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "qQPQXmBJX2cJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "896097fd-a567-4553-cb13-2220726694a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Text: Sense and Sensibility by Jane Austen 1811>\n"
          ]
        }
      ],
      "source": [
        "print(text2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "DKIvq6_3m0hu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504d98cb-39ad-43e0-ae29-4fcbe61cb214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Text: Sense and Sensibility by Jane Austen 1811>\n"
          ]
        }
      ],
      "source": [
        "# Now you try it by repeating this command, but using the imported\n",
        "# data object text2. Write a comment indicating what text2 contains.\n",
        "\n",
        "\n",
        "# 1.1: Your description of text2: Sense and Sensibility by Jane Austen 1811\n",
        "print(text2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "imavAwY23fWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1436710c-77b2-4727-a56d-d891dc07e775"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.text.Text"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "type(text1) # The type() command reveals the data type of an object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ao58rDlq42y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb0ab9e-d791-468c-9e67-88dbeae4dcce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__iadd__',\n",
              " '__imul__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__rmul__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'append',\n",
              " 'clear',\n",
              " 'copy',\n",
              " 'count',\n",
              " 'extend',\n",
              " 'index',\n",
              " 'insert',\n",
              " 'pop',\n",
              " 'remove',\n",
              " 'reverse',\n",
              " 'sort']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dir(sent1) # These are the attributes of the object\n",
        "# Check out how the end of the list shows all of the methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O0zrQaMi5eFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081ed5c8-f7b3-4f2d-bafa-591210074c2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Text.concordance of <Text: Moby Dick by Herman Melville 1851>>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Given the list above, we can find out more things about each attribute\n",
        "getattr(text1, \"concordance\")\n",
        "\n",
        "# <bound method Text.concordance of <Text: Moby Dick by Herman Melville 1851>>\n",
        "# A bound method is a function that is an attribute of a class and can be\n",
        "# called using an expression like : text1.concordance()\n",
        "# See the next section for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "QLW9IcHT35BJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4dabce-25a2-48d0-ef2f-71218ca0a370"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__iadd__',\n",
              " '__imul__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__rmul__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'append',\n",
              " 'clear',\n",
              " 'copy',\n",
              " 'count',\n",
              " 'extend',\n",
              " 'index',\n",
              " 'insert',\n",
              " 'pop',\n",
              " 'remove',\n",
              " 'reverse',\n",
              " 'sort']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "type(sent1) # What type is sent1\n",
        "# Now you add a line of code that shows the attributes of sent1\n",
        "\n",
        "# 1.2: Attributes of sent1\n",
        "\n",
        "dir(sent1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QRJ1VIUOX5T2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec62844-5d9e-4abc-cd0d-eb92ca106384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Call', 'me', 'Ishmael', '.']\n"
          ]
        }
      ],
      "source": [
        "print(sent1) # Lists are surrounded by [ and ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a0I4yxQM69a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44cf966-8929-4809-9cf7-07221e0f4af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.', 'Call', 'Ishmael', 'me']\n"
          ]
        }
      ],
      "source": [
        "sent1.sort() # This reorders the list alphabetically\n",
        "print(sent1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WcJW-2DF8Bz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577dd878-a01a-4c64-b76b-df6a01f2d2ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Call', 'Ishmael', 'me']\n"
          ]
        }
      ],
      "source": [
        "sent1.remove('.') # We can delete items by name\n",
        "print(sent1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YWow54JR8VqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5d7b84-d222-4830-878d-e3657862cfaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Call', 'Ishmael', 'me', '.']\n"
          ]
        }
      ],
      "source": [
        "sent1.append('.') # And we can add an item onto the end of the list\n",
        "print(sent1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7tNkiaFYYOXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c98c170-d1f8-4e2d-a329-038d0ca8295b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Call Ishmael me .\n"
          ]
        }
      ],
      "source": [
        "# The join method can be applied to\n",
        "sent1text = ' '.join(sent1) # You can glue elements of the list back together\n",
        "print(sent1text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zrVJGccsvIEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94fde236-a30c-4a67-921a-4b78015c9a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The family of Dashwood had long been settled in Sussex .\n"
          ]
        }
      ],
      "source": [
        "# Now you glue sent2 back together with spaces in between and then\n",
        "# print it (two lines of code).\n",
        "\n",
        "# 1.3: Reglue sent2 tokens\n",
        "\n",
        "sent2text = ' '.join(sent2) # You can glue elements of the list back together\n",
        "print(sent2text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj5hUFAkmHYw"
      },
      "source": [
        "**Searching**\n",
        "\n",
        "The text data structure from nltk has a number of bound methods. One is called concordance(), and it will search for any word that you give to the function and print the occurrences and some surrounding context. This function is just a diagnostic convenience, as you cannot save the results for later use. A more flexible way of searching uses the findall() method. Another function is “similar” which finds all the words that are used in the same context as the one given, where the context is the word before and the word after. We can also examine the contexts that are shared by two or more words, such as “monstrous” and “very” by using common_contexts. We have to enclose these words by square brackets as well as parentheses, and separate them with a comma. The output of common_contexts is a pair of words that surrounds both of the target words provided. For example if the target is very and the function returns a_pretty, the fragment in question would be \"a very pretty\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lXxugFXfRJlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c921cebd-b4e4-4dc6-8f99-bb893693d66e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 25 of 74 matches:\n",
            "eed her reported in the offing this morning ; a three years ' voyage , and a fu\n",
            "or who could tell but what the next morning , so soon as I popped out of the ro\n",
            "d Saturday night , or rather Sunday morning , in peddling his head around this \n",
            " The Counterpane . Upon waking next morning about daylight , I found Queequeg '\n",
            "ed away from me ; but waking in the morning , I shudderingly remembered it all \n",
            "t the first go off of a bitter cold morning . Seeing , now , that there were no\n",
            " wash himself . At that time in the morning any Christian would have washed his\n",
            "et , all wearing monkey jackets for morning gowns . You could pretty plainly te\n",
            "I did not . Returning from my first morning stroll , I again sallied out upon t\n",
            "d thrown over me upon waking in the morning , I thought this indifference of hi\n",
            "and chat over old times till nearly morning . Thus , then , in our hearts ' hon\n",
            "ing . CHAPTER 13 Wheelbarrow . Next morning , Monday , after disposing of the e\n",
            "d not at all account for , till one morning happening to take a stroll along th\n",
            "ere iron , and keep it for you till morning . But the chowder ; clam or cod to \n",
            " that trifling little affair . Next morning early , leaving Queequeg shut up wi\n",
            "doubting but that I had done a good morning ' s work , and that the Pequod was \n",
            " as any other men , God pity ' em ! Morning to ye , shipmates , morning ; the i\n",
            " ' em ! Morning to ye , shipmates , morning ; the ineffable heavens bless ye ; \n",
            "he man for him -- the likes of ye . Morning to ye , shipmates , morning ! Oh ! \n",
            "of ye . Morning to ye , shipmates , morning ! Oh ! when ye get there , tell ' e\n",
            "f he had a great secret in him .\" \" Morning to ye , shipmates , morning .\" \" Mo\n",
            "im .\" \" Morning to ye , shipmates , morning .\" \" Morning it is ,\" said I . \" Co\n",
            "ng to ye , shipmates , morning .\" \" Morning it is ,\" said I . \" Come along , Qu\n",
            "ship would certainly sail . So next morning , Queequeg and I took a very early \n",
            "y dim , very dim ,\" said Elijah . \" Morning to ye .\" Once more we quitted him ;\n"
          ]
        }
      ],
      "source": [
        "# searching text\n",
        "text1.concordance('morning')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WaAdHmOVFWQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c976d14c-46c4-4875-e7e7-cf0452850e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning; morning; morning;\n",
            "morning; morning; morning; morning; morning\n"
          ]
        }
      ],
      "source": [
        "# A more flexible capability is provided by findall(), which can use a\n",
        "# \"regular expression\" to find instances. Single tokens must be surrounded\n",
        "# by angle brackets < >\n",
        "text1.findall('<morning>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-7gbz4FDKOyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c88e85-5202-4b95-b5ee-7b56d5b340d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Morning to ye; Morning to ye; Morning to ye; Morning to ye; Morning to\n",
            "ye\n"
          ]
        }
      ],
      "source": [
        "# Note that these token specifications are case sensitive\n",
        "text1.findall('<Morning><to><ye>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nasu93P_KtZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69ffe27-ac6e-4dfe-dc9b-637bc69c865a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Morning to ye , shipmates; Morning to ye , shipmates; Morning to ye ,\n",
            "shipmates; Morning to ye .\" Once; Morning to ye ! morning\n"
          ]
        }
      ],
      "source": [
        "# We can also include two wildcard tokens to find out what comes next\n",
        "text1.findall('<Morning><to><ye><.*><.*>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "29_anrs4RJlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7da40ba-e550-45b0-f06a-769b03f8e50f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sea time whale ship man water voyage same moment world while hand word\n",
            "case lord day boat land days other\n"
          ]
        }
      ],
      "source": [
        "text1.similar('morning') # These words are used in the same context as morning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PMI__hpCRJlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998b86ca-d0d4-40b5-9c9c-7dc552efa8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day house time room world place matter cottage evening point country\n",
            "door and rest thing moment latter subject better letter\n"
          ]
        }
      ],
      "source": [
        "text2.similar('morning') # And here's the same thing for the second book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EJXhAOLHRJlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc738af4-5729-4a4d-ea6c-541f9e7713c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the_was this_i the_of the_marianne the_for the_before\n"
          ]
        }
      ],
      "source": [
        "# The use of the square brackets makes a list from the two words\n",
        "text2.common_contexts([\"morning\", \"evening\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "1vsmysnKoifn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd146f4-0c4e-482a-974c-9820c6ff5162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the_was this_i the_of the_marianne the_for the_before\n"
          ]
        }
      ],
      "source": [
        "# Now you try it by repeating the common_contexts command, but using the\n",
        "# data object text2. Use the terms morning and evening.\n",
        "\n",
        "text2.common_contexts([\"morning\", \"evening\"])\n",
        "\n",
        "# 1.4: Your explanation of the output: In text2 we will find sentences like \"the morning of\"/ \"the evening of\" / \"the evening was\" / \"the morning for\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7DHn6RGn6QM"
      },
      "source": [
        "**Word Counting**\n",
        "\n",
        "A natural question to ask in the analysis of a text is: how many words are there in the text? While it is straightforward for human beings to answer the question, it is not so for the computers. As a starting point, we can use Python function len to first count the total number of words and punctuation symbols that appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GpNt_O7WRJlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9890db5a-dc49-418c-fe13-4ee69ef44ee5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "260819"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Counting the total number of tokens\n",
        "len(text1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4znga5B2oHJG"
      },
      "source": [
        "How to interpret this number 260819? This means that there are 260,819 words and punctuation symbols, or \"tokens.\" A token is the technical name for a sequence of characters which is treated as a group by the program. Each text from the books was separated into a list of tokens, and this is one of the first NLP processing steps.\n",
        "\n",
        "Now this is the total number of tokens, and we might also want to find out how many distinct words there are, not counting repetitions. The Python “set” function removes the repetitions, and we can apply the “sorted” function to that, returning the resulted sorted list of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RnBCvkekRJlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e84ed88-bc84-4fd2-a06c-5066f01c1b3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!', '!\"', '!\"--', \"!'\", '!\\'\"', '!)', '!)\"', '!*', '!--', '!--\"']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "sorted(set(text1))[:10] # Review the first 10 of an alphabetized set of tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UddrbN6HMsr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7c6f9a-5ef8-4f65-e02d-0d2d52b02980"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Alone',\n",
              " 'Alps',\n",
              " 'Already',\n",
              " 'Also',\n",
              " 'Am',\n",
              " 'Ambergriese',\n",
              " 'Ambergris',\n",
              " 'Amelia',\n",
              " 'America',\n",
              " 'American']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Let's look at a few more, after we've gotten through the punctuation, numbers\n",
        "# and other stuff that appears early in the sort.\n",
        "sorted(set(text1))[400:410]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2x5lhq3lRJlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e266328c-3457-45e9-d21d-2f868c2f9e23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19317"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# The set() function creates an unordered collection\n",
        "# of elements where each element is unique.\n",
        "len(sorted(set(text1))) # Total number of tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Phn_dt-NRJlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7271f1-840f-4dbc-f8b7-dbf706bab608"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07406285585022564"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "len(set(text1)) / len(text1) # The size of the token set versus total tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LTFmY6mERJlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b56f446-73e4-4180-f0c2-646c97ca9684"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13721"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "text1.count(\"the\") # Count occurrences of one word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NN8U9PBNRJlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2900039b-3669-49e0-e3de-8232008d603f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.260736372733581"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Among tokens that are actual words, \"the\" is often one of the most common in\n",
        "# modern English.\n",
        "100 * text1.count('the')/len(text1) # As a percent of all tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8NK-bNsaRJlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7717421-9342-4aed-c98b-c750d560563e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.3096476867099405"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "100 * text1.count('and')/len(text1) # A more common word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VDB2via1NzJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17263013-f17d-4132-b6af-e1b6ff335d2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02607172023510557"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "100 * text1.count('morning')/len(text1) # Our example from above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AWLssPwCRJlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1980fe93-3d42-4c14-8ae2-816381ca80aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55208"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# This uses a list comprehension to cycle through all of the words in text1\n",
        "sixlettertokens = [w for w in text1 if len(w) >=6]\n",
        "len(sixlettertokens) # Count how many tokens are 6 letters or more"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "t07jd3sqRJlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a71b6a0-d938-4356-ab5b-6d9a22c05f9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141576"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "len(text2) # Now repeat the analyses above for text2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "id": "ozgMccJtRJlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725a204f-9837-4434-d3b6-980b004ce65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the token set versus total tokens =  0.04826383002768831\n",
            "The occurrences of the word 'the' as a percentage of all tokens =  2.727157145278861\n",
            "The occurrences of the word 'morning' as a percentage of all tokens =  0.061451093405661975\n",
            "How many tokens are 7 letters or more =  38097\n"
          ]
        }
      ],
      "source": [
        "# For text2, calculate the following quantities:\n",
        "\n",
        "# 1.5: The size of the token set versus total tokens (expressed as a proportion)\n",
        "print(\"The size of the token set versus total tokens = \",len(set(text2)) / len(text2))\n",
        "\n",
        "\n",
        "# 1.6: The occurrences of the word 'the' as a percentage of all tokens\n",
        "print(\"The occurrences of the word 'the' as a percentage of all tokens = \",100 * text2.count('the')/len(text2))\n",
        "\n",
        "# 1.7: The occurrences of the word 'morning' as a percentage of all tokens\n",
        "print(\"The occurrences of the word 'morning' as a percentage of all tokens = \",100 * text2.count('morning')/len(text2))\n",
        "\n",
        "\n",
        "# 1.8: How many tokens are 7 letters or more\n",
        "sevenlettertokens = [w for w in text1 if len(w) >6]\n",
        "print(\"How many tokens are 7 letters or more = \",len(sevenlettertokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "aR23u1bNO3sY"
      },
      "outputs": [],
      "source": [
        "# Here we are creating a custom function to integrate what we learned.\n",
        "def day_word_analysis(input_text):\n",
        "  \"\"\"\n",
        "  Find and print context for common time of day words.\n",
        "  Print an analysis of the occurrence of these words.\n",
        "  \"\"\"\n",
        "  input_text.concordance('morning', lines=3)\n",
        "  input_text.concordance('afternoon', lines=3)\n",
        "\n",
        "  m_count = input_text.count('morning')\n",
        "  a_count = input_text.count('afternoon')\n",
        "\n",
        "  print('Percentage of time of day words:',\n",
        "        100*(m_count + a_count)/len(input_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "MV_aDcy5QTlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842840c4-735b-4eac-e02e-c7ded4514087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 3 of 74 matches:\n",
            "eed her reported in the offing this morning ; a three years ' voyage , and a fu\n",
            "or who could tell but what the next morning , so soon as I popped out of the ro\n",
            "d Saturday night , or rather Sunday morning , in peddling his head around this \n",
            "Displaying 3 of 10 matches:\n",
            "-- GOLDSMITH TO JOHNSON . \" In the afternoon we saw what was supposed to be a r\n",
            "ulate the city of a dreamy Sabbath afternoon . Go from Corlears Hook to Coentie\n",
            "h it was only two o ' clock in the afternoon of the 21st June , the longest day\n",
            "Percentage of time of day words: 0.029905796740268154\n"
          ]
        }
      ],
      "source": [
        "day_word_analysis(text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rCo_613sQpFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90064b4-57d8-4f3e-f4e0-84fa7ad8f0f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 3 of 74 matches:\n",
            "eed her reported in the offing this morning ; a three years ' voyage , and a fu\n",
            "or who could tell but what the next morning , so soon as I popped out of the ro\n",
            "d Saturday night , or rather Sunday morning , in peddling his head around this \n",
            "Displaying 3 of 10 matches:\n",
            "-- GOLDSMITH TO JOHNSON . \" In the afternoon we saw what was supposed to be a r\n",
            "ulate the city of a dreamy Sabbath afternoon . Go from Corlears Hook to Coentie\n",
            "h it was only two o ' clock in the afternoon of the 21st June , the longest day\n",
            "Displaying 3 of 18 matches:\n",
            "I resolved to spend the rest of the evening as a looker on . Presently a riotin\n",
            "en only glows to be looked at ; the evening shades and phantoms gathering round\n",
            " them stay . He then went about his evening prayers , took out his idol , and r\n",
            "Percentage of time of day words: 0.03373987324543074\n",
            "\n",
            "\n",
            "Displaying 3 of 87 matches:\n",
            "e had been to several families that morning in hopes of procuring some addition\n",
            " together in the course of the last morning , and each time did he most unaccou\n",
            "Marianne and Margaret one memorable morning direct their steps , attracted by t\n",
            "Displaying 3 of 3 matches:\n",
            "moment , and we shall have a clear afternoon .\" Elinor was alternately diverted\n",
            "two happy hours with him yesterday afternoon , he would not hear of our parting\n",
            "with little intermission the whole afternoon , calming every fear , satisfying \n",
            "Displaying 3 of 51 matches:\n",
            "lone before the house , on the last evening of their being there ; \" when shall\n",
            "what related to themselves . In the evening , as Marianne was discovered to be \n",
            "ted it to be so , on the very first evening of their being together , from his \n",
            "Percentage of time of day words: 0.06568909984743176\n"
          ]
        }
      ],
      "source": [
        "# Now add 'evening' to day_word_analysis() and retest it.\n",
        "# Make sure to test with text1 and text2.\n",
        "\n",
        "def day_word_analysis(input_text):\n",
        "  \"\"\"\n",
        "  Find and print context for common time of day words.\n",
        "  Print an analysis of the occurrence of these words.\n",
        "  \"\"\"\n",
        "  input_text.concordance('morning', lines=3)\n",
        "  input_text.concordance('afternoon', lines=3)\n",
        "  input_text.concordance('evening', lines=3)\n",
        "\n",
        "  m_count = input_text.count('morning')\n",
        "  a_count = input_text.count('afternoon')\n",
        "  e_count = input_text.count('afternoon')\n",
        "\n",
        "\n",
        "  print('Percentage of time of day words:',\n",
        "        100*(m_count + a_count + e_count)/len(input_text))\n",
        "\n",
        "#print(\"Text 1 results\", day_word_analysis(text1))\n",
        "#print(\"Text 2 results\", day_word_analysis(text2))\n",
        "\n",
        "# 1.9: What do the results show?\n",
        "\n",
        "day_word_analysis(text1)\n",
        "print(\"\\n\")\n",
        "day_word_analysis(text2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "1Sx9_w048DAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2a09cc-7f96-4fd8-cecf-ecd81aed8e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 3 of 566 matches:\n",
            " had resolved never to be taught . Marianne ' s abilities were , in many respe\n",
            "had already imbibed a good deal of Marianne ' s romance , without having much \n",
            "hing . \" In a few months , my dear Marianne .\" said she , \" Elinor will , in a\n",
            "Displaying 3 of 36 matches:\n",
            "urage her to similar forbearance . Margaret , the other sister , was a good - \n",
            "ing in the opinion of Marianne and Margaret an absolute old bachelor , for he \n",
            "ne of these hills did Marianne and Margaret one memorable morning direct their\n",
            "Displaying 3 of 685 matches:\n",
            "avoid a breach with their brother . Elinor , this eldest daughter , whose advi\n",
            ", in many respects , quite equal to Elinor ' s . She was sensible and clever ;\n",
            "d her mother was strikingly great . Elinor saw , with concern , the excess of \n",
            "\n",
            "Percentage of time of Marianne: 0.39978527434028366\n",
            "\n",
            "Percentage of time of Margaret: 0.02542803865061875\n",
            "\n",
            "Percentage of time of Elinor: 0.48313273436175624\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1.10: Create a new function that discovers a different class of words\n",
        "# such as the names of characters in the story. Calculate the frequency of\n",
        "# occurrence of all the names together and also report which is the most\n",
        "# frequently used name.\n",
        "\n",
        "\n",
        "def names_analysis(input_text):\n",
        "  \"\"\"\n",
        "  Find and print context for common names used in the text.\n",
        "  Print an analysis of the occurrence of these words.\n",
        "  \"\"\"\n",
        "  input_text.concordance('Marianne', lines=3)\n",
        "  input_text.concordance('Margaret', lines=3)\n",
        "  input_text.concordance('Elinor', lines=3)\n",
        "\n",
        "  marianne_count = input_text.count('Marianne')\n",
        "  margaret_count = input_text.count('Margaret')\n",
        "  elinor_count = input_text.count('Elinor')\n",
        "\n",
        "\n",
        "  print('\\nPercentage of time of Marianne:',\n",
        "        100*(marianne_count)/len(input_text))\n",
        "  print('\\nPercentage of time of Margaret:',\n",
        "        100*(margaret_count)/len(input_text))\n",
        "  print('\\nPercentage of time of Elinor:',\n",
        "        100*(elinor_count)/len(input_text))\n",
        "\n",
        "names_analysis(text2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "84RXJBcWU1Xk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}